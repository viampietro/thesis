In this section, we formalize a specific simulation algorithm for the
\hvhdl{} designs. This algorithm is much simpler than the one
presented in the LRM. This is mostly due to the fact that \hvhdl{} is
a subset of VHDL that aims at the description of synthesizable and
synchronous designs. Synthesizable designs mean that the only kind of
signal assignment used to describe the design behaviors are
$\delta$-delay signal assignments. Leaving apart the synchronous side,
we only need a simulation algorithm that performs \textit{delta
  cycles} (see Section~\ref{sec:vhdl-informal-sem}) to simulate such
synthesizable designs. However, \hvhdl{} designs are also synchronous
designs. As such, an \hvhdl{} design is equipped with a clock input
port. The value of the clock input port changes from 0 to 1 and
inversely at constant rate, i.e. the clock rate. One can see the
changing of the value of the clock input port as the result of the
execution of a unit-delay signal assignment where the time clause is
equal to half the clock period. Listing~\ref{lst:clk-unit-delay}
illustrates how a \hvhdl{} design \texttt{tl} can be embedded in
another top-level design with a process regulating the value of a
clock signal by using a unit-delay signal
assignment. Listing~\ref{lst:clk-unit-delay} presents the behavioral
part of the architecture of the embedding top-level design.

\begin{lstlisting}[language=VHDL,label={lst:clk-unit-delay},
caption={[]},framexleftmargin=1.5em,xleftmargin=2em,numbers=left,
numberstyle=\tiny\ttfamily]
architecture toplevel_arch of toplevel is
begin 

  clkp : process (clock)
  begin 
    clock <= not clock after $\tau$ -- where $\tau$ is half a clock period
  end process clkp;

  $id_{tl}$ : entity tl 
  generic map (#\dots#)
  port map (clock => clock, #\dots#);

end toplevel_arch;
\end{lstlisting}

In Listing~\ref{lst:clk-unit-delay}, the \texttt{clkp} process assigns
the clock signal with its inverse value after $\tau$ unit of time
where $\tau$ corresponds to half the clock period. Of course, the
clock period is specified by the designer of the circuit. The
component instance $id_{tl}$ corresponds to the instantiation of the
\hvhdl{} design \texttt{tl}, i.e. the one we want to simulate. The
\texttt{clock} input port of $id_{tl}$ is connected to the
\texttt{clock} signal of the embedding design. Thus, when the value of
the clock signal changes every half clock period, the processes that
react to the changes of the clock signal, i.e. the so-called
\emph{synchronous} processes, are executed in the body of component
instance $id_{tl}$. Then, it is the turn of \emph{combinational}
processes, i.e. processes that follow the combinational logic and thus
do not react to the changes of the clock signal, to be executed until
stabilization of all signal values. Using the terms of the LRM
simulation algorithm, what will happen when trying to simulate the
design of Listing~\ref{lst:clk-unit-delay} will be an alternation
between one time cycle to move to the next clock event and execute
synchronous processes, followed by many delta cycles corresponding to
the execution of combinational processes until stabilization. Thus, we
choose to embed this alternation within the definition of our
simulation algorithm.

We must add a last element to the definition of our simulation
algorithm. The top-level designs generated by the \hilecop{}
transformation interact with their environment through their input
ports. The input ports of a top-level design are called \emph{primary}
input ports. In our simulation algorithm, we need to represent  the
capture and the injection of the values of primary input ports and how
this affect the values of the internal signals of the simulated
design. 

Finally, Algorithm~\ref{alg:simulation} gives an overview in a
pseudo-code language of our simulation algorithm. This simulation
algorithm is formalized in a small-step semantics style in the
following sections.

\begin{algorithm}[H]
  \DontPrintSemicolon

  \SetAlFnt{\fontsize{11}{13}\selectfont}
  
  \SetAlCapFnt{\fontsize{11}{13}\selectfont}
  \SetAlCapNameFnt{\fontsize{11}{13}\selectfont}
  % \NoCaptionOfAlgo

  \caption{Simulation($\Delta$, $\sigma_{e}$, $cs$, $E_p$, $nbOfCycles$)}
  \label{alg:simulation}
  
  \AlFnt % overriding the new font
  
  \tcp{\textcolor{red}{Initialization phase.}}
  $\sigma_e'\leftarrow$ \texttt{RunAllOnce($\Delta$,$\sigma_{e}$,$cs$)}\; 
  $\sigma\leftarrow$ \texttt{Stabilize($\Delta$,$\sigma_e'$,$cs$)}\;
  \BlankLine
  
  \tcp{\textcolor{red}{Main loop.}}
  $T_c\leftarrow{}0$\; \label{line:init-tc}
  $\theta\leftarrow[\sigma]$\; \label{line:init-trace}
  
  \BlankLine

  \While{$T_c\le{}nbOfCycles$}{
    $\sigma_i\leftarrow$ \texttt{Inject$_\uparrow$($\Delta$,$\sigma$,$E_p$,$T_c$)}\;
    $\sigma_\uparrow\leftarrow$ \texttt{RisingEdge($\Delta$,$\sigma_i$,$cs$)}\;
    $\sigma'\leftarrow$ \texttt{Stabilize($\Delta$,$\sigma_\uparrow$,$cs$)}\;
    $\sigma'_i\leftarrow$ \texttt{Inject$_\downarrow$($\Delta$,$\sigma'$,$E_p$,$T_c$)}\;
    $\sigma_\downarrow\leftarrow$ \texttt{FallingEdge($\Delta$,$\sigma'_i$,$cs$)}\;
    $\sigma\leftarrow$ \texttt{Stabilize($\Delta$,$\sigma_\downarrow$,$cs$)}\;

    \BlankLine
    $\theta\leftarrow\theta\mdoubleplus[\sigma',\sigma]$\; \label{line:append-states}
    $T_c\leftarrow{}T_c+1$\;
  }

  \Return{$\theta$}\;
\end{algorithm}

Algorithm~\ref{alg:simulation} defines an elaborated design $\Delta$
and a default design state $\sigma_e$ as parameters. We assume that
they are the result of the elaboration of the design being
simulated. $cs$ corresponds to the behavior of the design, i.e. the
one that will be executed during the simulation. $E_p$ is the
environment that will provide values to the primary input
ports. $nbOfCycles$ corresponds to the number of simulation cycles to
be performed. Algorithm~\ref{alg:simulation} begins with an
initialization phase (following the LRM simulation algorithm); all
processes are run excatly once followed by a stabilization phase
(multiple delta cycles). Line~\ref{line:init-tc} initializes the
variable $T_c$ to zero. $T_c$ represents the current count of
simulation cycles. Line~\ref{line:init-trace} initializes the variable
$\theta$ with a singleton list holding state $\sigma$, i.e. the
initial simulation state. Then, the same loop is performed until $T_c$
reaches the prescribed number of simulation cycles. First, the values
of primary input ports are retrieved from the environment $E_p$ for
the current count $T_c$ and the current clock event (i.e. either
$\uparrow$ or $\downarrow$); this is performed by the
\texttt{Inject}$_\uparrow$ (resp. \texttt{Inject}$_\downarrow$) at the
rising edge of the clock; then, all parts of $cs$ that react to the
rising edge (resp. falling edge) of the clock signal are executed;
finally, the combinational parts of $cs$ are executed until
stabilization of all signals. At Line~\ref{line:append-states}, the
states obtained at the middle and at the end of the clock cycle are
appended to the simulation trace $\theta$. Note that we only register
stable states in the simulation trace. To conclude the simulation
cycle, the current count is incremented. After the execution of all
simulatin cycles, Algorithm~\ref{alg:simulation} returns the
simulation trace.

\subsection{Full simulation}

The full simulation process is decomposed in two steps. The first step
is the elaboration phase that builds an elaborated version of a
\hvhdl{} design along with its default state, and type-checks the
design. Previous to the elaboration phase, the top-level design
receives a value for each of its generic constant; we refer to it as
the \emph{dimensioning} of the top-level design. The second step is
the simulation phase that executes the behavioral part of the
top-level design starting from an initial state. The simulation is
decomposed into simulation cycles. Each simulation cycle is divided in
four parts entailed by the \emph{synchronous} execution of
$\mathcal{H}$-VHDL top-level designs, i.e designs whose behavior
depend on a clock signal. The four parts are, first, the execution of
concurrent statements responding to the rising edge of the clock
signal, then, a phase of signal stabilization followed by the
execution of concurrent statements responding to the falling edge of
the clock signal, and finally another phase of signal
stabilization. At each clock event, the value of the primary inputs of
the design being currrently simulated are captured and injected in the
simulation; primary inputs receive values from the design
environment. Here, the environment is represented by a function
mapping input port identifiers to values depending on the current
count of simulation cycles and the considered clock event. This leads
to the following hypothesis:

\begin{hypothesis}[Stable primary inputs]
  \label{hyp:stable-pi}
  The values of primary inputs (i.e, input ports of the top-level
  design) are captured at each clock event, and therefore are stable
  (i.e, their values do not change) between two contiguous clock
  events.
\end{hypothesis}

Hypothesis~\ref{hyp:stable-pi} arises from the fact that the clock
signal sample rate respects the Nyquist-Shannon sampling
theorem. Therefore, the sample rate of the design's clock is
sufficient to capture all events possibly arising in the environment.
We only need to settle the values of the primary inputs at the clock
edges.

Also, after each clock event phase follows a signal stabilization
phase in the proceedings of a simulation cycle. One more hypothesis is
needed here:

\begin{hypothesis}[Stabilization]
  \label{hyp:stabilization}
  All signals have enough time to stabilize during the signal
  stabilization phase that happens between two clock events.
\end{hypothesis}

As a \hvhdl{} design represents a physical circuit, one can assume
that the represented circuit is analyzed former to the simulation.
Therefore, one knows exactly how much time is needed to propagate
signal values through the longest physical path; as a consequence, a
proper clock frequency is set ensuring signal stabilization between
two clock events. Thus, Hypothesis~\ref{hyp:stabilization} arises from
the latter facts.

%%% DESIGN ELABORATION AND SIMULATION.

The $full$ simulation relation takes in parameter a top-level design
d, a design store $\mathcal{D}\in{}id\nrightarrow{}design$, an
elaborated design $\Delta\in{}ElDesign(d)$, a dimensioning function
$\mathcal{M}_g\in{}Gens(\Delta)\nrightarrow{}value$, a primary input
environment
$E_p\in{}(\mathbb{N}\times{}Clk)\rightarrow{}(Ins(\Delta)\rightarrow{}value)$,
a simulation cycle count $\tau\in\mathbb{N}$, and a simulation trace
$\theta\in{}\mathtt{list}(\Sigma(\Delta))$, corresponding to the list
of states yielded by the simulation of design d after $\tau$
cycles. Note that we use the pointed notation to access the behavioral
part of design d, written d.cs. It is this part of the design that is
executed during the simulation, and therefore is passed as a parameter
of the initialization and simulation relations. % The states in
% $\sigma_t$ are \emph{time}-ordered, that is, the first states of the
% list are the earliest states in the simulation history. To achieve
% conciseness, further on a singleton trace containing the only element
% $\sigma$ is written $\sigma$. The trace resulting of the concatenation
% of two traces $\sigma_t$ and $\sigma_t'$ is written
% $\sigma_t.\sigma_t'$.

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{FullSim}}
  
  \begin{prooftree}[template=\inserttext]

    % Design elab.
    \hypo{$\mathcal{D},\mathcal{M}_g\vdash\mathrm{d}\xrightarrow{elab}\Delta,\sigma$}

    % Initialization.
    \hypo{$\mathcal{D},\Delta,\sigma\vdash{}\mathrm{d.cs}\xrightarrow{init}\sigma_0$}
       
    % Simulation loop.
    \hypo{$\mathcal{D},E_p,\Delta,\tau,\sigma_0\vdash{}\mathrm{d.cs}\rightarrow\theta$}
    
    \infer3 [] { $\mathcal{D},\Delta,\mathcal{M}_g,E_p,\tau\vdash$
      $\mathrm{d}\xrightarrow{full}(\sigma_0::\theta)$ }
  \end{prooftree}
\end{table}

\noindent{}where:

\begin{itemize}[label=-]
\item $\mathcal{M}_g\in{}Gens(\Delta)\nrightarrow{}value$, the
  function yelding the values of generic constants for a given
  top-level design, refered to as the \emph{dimensioning}
  function. Here, $Gens(\Delta)$ denotes the domain of $Gens(\Delta)$,
  i.e. the set of generic constant identifiers of $\Delta$.
\item
  $E_p\in{}(\mathbb{N}\times{}Clk)\rightarrow{}(Ins(\Delta)\rightarrow{}value)$,
  the function yelding a mapping from primary inputs (i.e, input ports
  of the top-level design) to values at a given simulation cycle count
  (i.e, the $\mathbb{N}$ argument), and a given clock event (i.e, the
  $Clk$ argument, where $Clk=\{\uparrow,\downarrow\}$). Here,
  $Ins(\Delta)$ denotes the domain of $Ins(\Delta)$, i.e. the set of
  input port identifiers of $\Delta$.
\item $\tau$, the number of simulation cycles to execute.  The value
  of $\tau$ is decremented at each clock cycle until it reaches zero
  (see Section~\ref{sec:sim-loop}).
\end{itemize}

\subsection{Simulation loop}
\label{sec:sim-loop}

The following rules define the \hvhdl{} simulation relation. The
\hvhdl{} simulation relation associates the execution of a behavior
$cs$ with a simulation trace $\theta$ in a context
$\mathcal{D},E_p,\Delta,\tau,\sigma$. The simulation trace $\theta$ is
the result of the execution of the design behavior $cs$ during $\tau$
cycles. In the case where $\tau$ is equal zero (Rule~\textsc{SimEnd}),
the execution of $cs$ returns an empty trace. In the case where $\tau$
is greater than zero (Rule~\textsc{SimLoop}), one simulation cycle is
performed from the starting state $\sigma$ and returns the two states:
$\sigma'$, the state in the middle of the clock cycle, and $\sigma''$,
the state at the end of the clock cycle. Then, the \hvhdl{} simulation
relation calls itself recursively with a decremented cycle count
$\tau$. The recursive call yields a trace $\theta$ which is then
appended to the states $\sigma'$ and $\sigma''$ to form the final
simulation trace.

\begin{table}[H]

  \begin{tabular}{@{}l}
    %%% SIMULATION END.
    
    {\fontsize{10}{13}\selectfont\textsc{SimEnd}} \\
    
    {\begin{prooftree}[template=\inserttext]
        \infer0 {
          $\mathcal{D},E_p,\Delta,0,\sigma\vdash{}cs\rightarrow{}[~]$
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    % SIMULATION LOOP
    
    {\fontsize{10}{13}\selectfont\textsc{SimLoop}} \\
    
    {\begin{prooftree}[template=\inserttext]
        
        % First column.
        \hypo{$\mathcal{D},E_p,\Delta,\tau,\sigma\vdash{}cs\xrightarrow{\uparrow,\downarrow}\sigma',\sigma''$}

        % Second column.
        \hypo{$\mathcal{D},E_p,\Delta,\tau-1,\sigma''\vdash{}cs\rightarrow\theta$}
        
        \infer2 [$\tau>0$] {
          $\mathcal{D},E_p,\Delta,\tau,\sigma\vdash{}cs\rightarrow(\sigma'
          :: \sigma'' :: \theta)$ }
      \end{prooftree}} \\
  \end{tabular}

\end{table}

\subsection{Simulation cycle}

 To ease the reading of
forward simulation rules, we need to introduce two notations.

\begin{notation}[Overriding union]
  For all partial function $f,f'\in{}X\nrightarrow{}Y$, $f\ocup{}f'$
  denotes the overriding union of $f$ and $f'$ such that
  $f\ocup{}f'(x)=
  \begin{cases}
    f'(x) & if~x\in\mathtt{dom}(f') \\
    f(x) & otherwise \\
  \end{cases}
  $
\end{notation}

\begin{notation}[Differentiated intersection domain]
  For all partial function $f,f'\in{}X\nrightarrow{}Y$, $f\dcap{}f'$
  denotes the intersection of the domain of $f$ and $f'$ for which $f$
  and $f'$ yields different values. That is,
  $f\dcap{}f'=\{~x\in\mathtt{dom}(f)\cap\mathtt{dom}(f')~|~f(x)\neq{}f'(x)~\}$.
\end{notation}

\begin{definition}[Input port values update]
  Given an \hvhdl{} design $d\in{}design$, a design store
  $\mathcal{D}\in{}id\nrightarrow{}design$, an elaborated design
  $\Delta\in{}ElDesign(d,\mathcal{D})$, a simulation environment
  $E_p\in{}(\mathbb{N}\times\{\uparrow,\downarrow\})\rightarrow(Ins(\Delta)\rightarrow{}value)$,
  let us define the relation expressing the update of the values of
  the input ports of $\Delta$ at a given design state
  $\sigma\in\Sigma(\Delta)$, clock cycle count $\tau\in{}\mathbb{N}$,
  and clock event $clk\in\{\uparrow,\downarrow\}$, and thus resulting
  in a new state $\sigma_i\in\Sigma(\Delta)$. The relation is written
  $\mathtt{Inject}_{clk}(\sigma,E_p,\tau,\sigma_i)$ and verifies that:
  $\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ and
  $\sigma_i={<}\mathcal{S}\ocup{}E_p(\tau,clk),\mathcal{C},\mathcal{E}{>}$.
\end{definition}

The \hvhdl{} simulation cycle relation is defined through the only
Rule~\textsc{SimCyc}. It states that the design states $\sigma'$ and
$\sigma''$ are the result of the execution of the design behavior $cs$
over one simulation cycle, this starting from state $\sigma$. Here,
$\sigma'$ is the state obtained in the middle of the clock cycle,
i.e. after the rising edge phase and the first stabilization phase,
and $\sigma''$ is the state obtained at the end of the clock cycle,
i.e. after the falling edge phase and the second stabilization phase.
As told in Hypothesis~\ref{hyp:stable-pi}, the update of the value of
input ports is performed at each clock event. New input port values
are coming from the environment $E_p$. The updates are made through
the definitions of states $\sigma_i$ and $\sigma'_i$ which are
qualified in the side conditions by the $\mathtt{Inject}_{\uparrow}$
and $\mathtt{Inject}_{\downarrow}$ relations.

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{SimCyc}}
  
  \begin{prooftree}[template=\inserttext]

    % Rising
    \hypo{$\mathcal{D},\Delta,\sigma_i\vdash\mathrm{cs}\xrightarrow{\uparrow}\sigma_\uparrow$}
    
    % Falling
    \infer[no rule]1{$\mathcal{D},\Delta,\sigma'_i\vdash\mathrm{cs}\xrightarrow{\downarrow}\sigma_\downarrow$}

    % Stabilize after rising.
    \hypo{$\mathcal{D},\Delta,\sigma_\uparrow\vdash\mathrm{cs}\xrightarrow{\rightsquigarrow}\sigma'$}

    % Stabilize after falling.
    \infer[no rule]1{$\mathcal{D},\Delta,\sigma_\downarrow\vdash\mathrm{cs}\xrightarrow{\rightsquigarrow}\sigma''$}
    
    \infer2
    [{
      \renewcommand{\arraystretch}{1.5}
      \begin{tabular}{@{}l}
        $\mathtt{Inject}_\uparrow(\sigma,E_p,\tau,\sigma_i)$\\
        $\mathtt{Inject}_\downarrow(\sigma',E_p,\tau,\sigma'_i)$\\
      \end{tabular}
    }] {
      $\mathcal{D},E_p,\Delta,\tau,\sigma\vdash\mathrm{cs}\xrightarrow{\uparrow,\downarrow}$
      $\sigma',\sigma''$ }
  \end{prooftree}
\end{table}

\subsection{Initialization rules}
\label{sec:init-rules}

The $init$ relation, defined through the only Rule~\textsc{Init},
describes the initialization phase of the \hvhdl{} simulation
algorithm. It produces an initial simulation state $\sigma_0$ by
executing the design behavior $cs$ in the context
$\mathcal{D},\Delta,\sigma$.

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{Init}}
  
  \begin{prooftree}[template=\inserttext]

    % Run all processes once.
    \hypo{$\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{runinit}{}\sigma'$}

    % Stabilization phase after runinit.
    \hypo{$\mathcal{D},\Delta,\sigma'\vdash\mathrm{cs}\xrightarrow{\rightsquigarrow}{}\sigma_0$}

    % Conclusion.
    \infer2
    {
      $\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{init}\sigma_0$
    }

  \end{prooftree}
\end{table}

During the initialization phase, each process is executed exactly
once. This is formalized by the $runinit$ relation. Then a
stabilization phase follows, formalized by the $stabilize$ relation,
i.e. $\xrightarrow{\rightsquigarrow}$. The initialization phase
triggers the execution of the first part of reset blocks. A reset
block (\vhdle|rst| ss ss') is equivalent to (\vhdle|if rst = '0' then|
ss \vhdle|else| ss' \vhdle|end if;|).  Therefore, when considering a
(\texttt{rst} ss ss') block, the $runinit$ relation always executes
the ss block; at every other moment of the simulation, the ss' block
is executed. This mimicks the conventional proceeding of a simulation
where a \textit{reset} signal set to false triggers the initialization
of the simulated system, and then is set to true for the rest of the
simulation.

The $runinit$ relation is defined by the Rules~\textsc{PsRunInit},
\textsc{CompRunInit}, \textsc{ParRunInit} and
\textsc{NullRunInit}. The $stabilize$ relation is defined in
Section~\ref{sec:stab-rules}.

\subsubsection{Evaluation of a process statement}
\label{subsubsec:ps-stmt-init}

The \textsc{PsRunInit} rule describes the execution of a process
statement during the initialization phase. The execution of a process
statement comes down to the execution of the process statement
body. The result of the execution is a new state $\sigma'$.

\begin{premises}
  \begin{itemize}
  \item The $i$ flag of the $ss_i$ relation indicates that all
    sequential statements responding to the initialization phase (i.e,
    reset blocks) will be executed.
  \item The $ss_i$ relation takes two states in its context, i.e. two
    $\sigma$. The first $\sigma$ is the state used to evaluate
    expressions appearing in the process statement body; the second
    $\sigma$ is the state that will be modified by the execution of
    signal assignment statements.

\end{itemize}
\end{premises}

\begin{sideconds}
  The local environment $\Lambda$ used to execute the body of the
  process $\mathrm{id}_p$ is retrieved from the $Ps$ sub-environment
  of the elaborated design $\Delta$.
\end{sideconds}

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{PsRunInit}} \\
    {\begin{prooftree}[template=\inserttext]
        
        % Runs seq.
        \hypo{$\Delta,\sigma,\sigma,\Lambda\vdash\mathrm{ss}\xrightarrow{ss_i}{}\sigma',\Lambda'$}

        % Conlcusion.
        \infer1
        [{
          \begin{tabular}{@{}l}
            $\Delta(\mathrm{id}_p)=\Lambda$\\
          \end{tabular}
        }]
        {
          $\mathcal{D},\Delta,\sigma\vdash$
          \vhdle|process| \texttt{(}id$_p$\texttt{,} sl\texttt{,} vars\texttt{,} ss\texttt{)}
          $\xrightarrow{runinit}\sigma'$
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Evaluation of a component instantiation statement}
\label{subsubsec:ci-stmt-init}

Rule~\textsc{CompRunInit} describes the execution of a component
instantiation statement during the initialization phase. The execution
of a component instantiation statement is divided in three
phases. First, the input ports of the component instance receive new
values through the evaluation of the component instance input port
map. Second, the internal behavior of the component instance is
evaluated; this evaluation possibly modifies the value of the internal
signals and the output ports of the component instance. Finally,
through the evaluation of its output port map, the component instance
propagates the value of its output ports to the signals of the
embedding design.

\begin{premises}
  \begin{itemize}
  \item The $mapip$ relation evaluates the input port map i of
    $\mathrm{id}_c$, thus modifying the internal state $\sigma_c$ of
    $\mathrm{id}_c$. The result is a new internal state $\sigma'_c$.
  \item The expression $\mathcal{D}(\mathrm{id}_e).\mathrm{cs}$ refers
    to the internal behavior of the component instance
    $\mathrm{id}_c$.
  \item State $\sigma_c''$ is the new internal state of component
    instance $\mathrm{id}_c$ resulting from the execution of the
    internal behavior of $\mathrm{id}_c$.
  \item The $mapop$ relation evaluates the output port map o of
    $\mathrm{id}_c$, thus modifying the state $\sigma$ of the
    embedding design. The result is a new embedding design state
    $\sigma'$.
  \end{itemize}
\end{premises}

\begin{sideconds}
  \begin{itemize}
  \item $\Delta_c$ is the elaborated version of the component instance
    $\mathrm{id}_c$ referenced in the $Comps$ sub-environment of the
    embedding design $\Delta$, i.e. $\Delta(id_c)=\Delta_c$.
  \item $\sigma_c$ is the internal design state of the component
    instance $\mathrm{id}_c$ referenced in the component store of
    state $\sigma$, i.e. $\sigma(id_c)=\sigma_c$.
  \item The component store $\mathcal{C}''$ of state $\sigma''$ is
    equal to the component store $\mathcal{C}'$ of state $\sigma'$
    where the component instance $\mathrm{id}_c$ is assigned to its
    new internal state $\sigma_c''$.
  \item The expression $\mathcal{C}\dcap\mathcal{C}''$ equals
    $\{\mathrm{id}_c\}$ if the internal state of component state
    $id_c$ has changed after the evaluation of its input port map and
    its internal behavior. In other words, we register the component
    instance $\mathrm{id}_c$ as an eventful component instance if
    $\sigma_c\neq\sigma_c''$.
  \end{itemize}
\end{sideconds}


\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{CompRunInit}} \\
    {\begin{prooftree}
        
        % Builds mapping for in ports.
        \hypo{\Delta,\Delta_c,\sigma,\sigma_c\vdash\mathrm{i}\xrightarrow{mapip}\sigma'_c}
        
        % Executes runinit on component behavior.
        \infer[no rule]1{\mathcal{D},\Delta_c,\sigma_c'\vdash{}\mathcal{D}(\mathrm{id_e}).\mathrm{cs}\xrightarrow{runinit}\sigma_c''}
        
        % Builds mapping for out ports.
        \infer[no rule]1{
          \Delta,\Delta_c,\sigma,\sigma_c''\vdash
          \mathrm{o}
          \xrightarrow{mapop}
          \sigma'
        }
        
        % Conclusion.
        \infer1
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_e\in\mathcal{D}$ \\
            $\Delta(\mathrm{id}_c)=\Delta_c$, $\sigma(\mathrm{id}_c)=\sigma_c$ \\
            $\sigma''={<}\mathcal{S}',\mathcal{C}'',\mathcal{E}'\cup(\mathcal{C}\dcap\mathcal{C}''){>}$ \\
            $\mathcal{C}''=\mathcal{C}'(\mathrm{id}_c)\leftarrow\sigma_c''$
          \end{tabular}
        }] {
          \mathcal{D},\Delta,\sigma\vdash~
          $\vhdle|comp|$~(\mathrm{id}_c, \mathrm{id}_e, \mathrm{g},
          \mathrm{i}, \mathrm{o})
          \xrightarrow{runinit}{}\sigma''
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Evaluation of the composition of concurrent statements}
\label{subsubsec:ps-stmt-init}

Rule~\textsc{ParRunInit} describes the evaluation of the parallel
composition of two concurrent statements cs and cs'. The two
concurrent statements are evaluated starting from the same state
$\sigma$ and they generate two different state $\sigma'$ and
$\sigma''$. The state resulting from the concurrent execution of cs
and cs' is the result of a merging between the starting state
$\sigma$, and the two states $\sigma'$ and $\sigma''$.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{ParRunInit}} \\
    {\begin{prooftree}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{runinit}\sigma'}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs'}\xrightarrow{runinit}\sigma''}
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l@{}}
            $\mathcal{E}'\cap\mathcal{E}''=\emptyset$ \\
          \end{tabular}
        }] {
          \mathcal{D},\Delta,\sigma\vdash\mathrm{cs}~\mathtt{||}~\mathrm{cs'}\xrightarrow{runinit}\mathtt{merge}(\sigma,\sigma',\sigma'')
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

The \texttt{merge} function computes a new state based on the original
state \textit{o}, and the states \textit{s} and \textit{s'} yielded by
the computation of two concurrent statements. In the resulting state,
the signal value store $\mathcal{S}_m$ is a function merging together
the signal store functions at state $o$, $s$ and $s'$. $S_m$ yields
values from the signal store $\mathcal{S}$ (resp. $\mathcal{S}'$) for
all signal that belongs to the set of events at state $s$
(resp. $s'$), and yields values from the original signal store
$\mathcal{S}_o$ for all unchanged signals. The same goes for the
resulting component instance state store $C_m$. The new set of events
$\mathcal{E}_m$ is the union between set of events at state $s$ and
$s'$. The \texttt{merge} correctly merges the state $o$, $s$ and $s'$
only if the set of events of $s$ and $s'$ are disjoint. The
\textsc{ParRunInit} rule that appeals to the \texttt{merge} function
defines the condition of disjoint set of events as a side condition.

\begin{table}[H]
\begin{lstlisting}[language=PseudoCoq]
Definition merge(o,s,s') :=
   let o = ($\mathcal{S}_o$,$\mathcal{C}_o$,$\mathcal{E}_o$) in
   let s = ($\mathcal{S}$,$\mathcal{C}$,$\mathcal{E}$) in
   let s' = ($\mathcal{S}'$,$\mathcal{C}'$,$\mathcal{E}'$) in
   let $\mathcal{S}_m$ = $\lambda\mathrm{id}.$ if $\mathrm{id}\in\mathcal{E}$ then $\mathcal{S}(\mathrm{id})$ else if $\mathrm{id}\in\mathcal{E}'$ then $\mathcal{S}'(\mathrm{id})$ else $\mathcal{S}_o(\mathrm{id})$
   let $\mathcal{C}_m$ = $\lambda\mathrm{id}.$ if $\mathrm{id}\in\mathcal{E}$ then $\mathcal{C}(\mathrm{id})$ else if $\mathrm{id}\in\mathcal{E}'$ then $\mathcal{C}'(\mathrm{id})$ else $\mathcal{C}_o(\mathrm{id})$
   let $\mathcal{E}_m$ = $\mathcal{E}\cup\mathcal{E}'$ in ($\mathcal{S}_m$,$\mathcal{C}_m$,$\mathcal{E}_m$).
\end{lstlisting}
\end{table}

\begin{remark}[No multiply-driven signals]
  For all states $\sigma=(\mathcal{S},\mathcal{C},\mathcal{E})$ and
  $\sigma'=(\mathcal{S}',\mathcal{C}',\mathcal{E}')$ resulting from
  the execution of two concurrent statements cs and cs',
  $\mathcal{E}\cap\mathcal{E}'=\emptyset$. Otherwise, there exists
  some multiply-driven signals, which are forbidden in our semantics.
\end{remark}

In the formalization of the \hvhdl{} simulation algorithm, the set of
events of a design state is only useful to merge the states resulting
from the execution of multiple concurrent statements. In the LRM
simulation algorithm, the kernel process uses the set of events to
resume the activity of processes. If one of the signal declared in a
process' sensitivity list is registered in the current set of events,
then the process body must be executed. We choose to disregard this
aspect of the execution of process in the formalization of our
simulation algorithm (see Section~\ref{sec:stab-rules} about the
definition of stabilization rules).

Rule~\textsc{NullRunInit} evaluates a null statement during the
initialization phase. The evaluation of a null statement yields a
state similar to the starting state but with an empty event set.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{NullRunInit}} \\
    {\begin{prooftree}
        \infer0
        {
          \Delta,\sigma\vdash\mathtt{null}\xrightarrow{runinit}NoEv(\sigma)
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsection{Clock phases rules}
\label{sec:clk-phases-rules}

The following rules express the evaluation of concurrent statements at
clock phases, i.e, the $\uparrow$ and $\downarrow$ phases. The clock
signal, trigerring the evaluation of synchronous process statements,
is represented by the reserved signal identifier \texttt{clk}. Thus,
synchronous processes are processes containing the \texttt{clk} in
their sensitivity list.

\subsubsection{Evaluation of a process statement}

The following rules describe the evaluation of a process statement at
the occurrence of the rising or the falling edge of the clock
signal. In the case where a process does not contain the \texttt{clk}
identifier in its sensitivity list, then its statement body is not
executed during the clock phases (see Rules~\textsc{PsRENoClk} and
\textsc{PsFENoClk}). Otherwise, its statement body is
executed. Depending on the considered clock event, falling blocks or
rising blocks are executed when encountered in the body of a process
(see Rules~\textsc{PsREClk} and \textsc{PsFEClk}).

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{PsRENoClk}}
  
  \begin{prooftree}[template=\inserttext]
    \hypo{}

    \infer1
    [$\mathtt{clk}\notin\mathrm{sl}$]
    {
      $\mathcal{D},\Delta,\sigma\vdash$
      \vhdle|process| \texttt{(}id$_p$\texttt{,} sl\texttt{,} vars\texttt{,} ss\texttt{)}
      $\xrightarrow{\uparrow}$
      $\sigma$
    }
  \end{prooftree}
\end{table}

\begin{premises}
  The $\uparrow$ flag in the $ss_\uparrow$ relation indicates that
  $\mathtt{rising}$ blocks will be executed.
\end{premises}

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{PsREClk}}
  
  \begin{prooftree}[template=\inserttext]

    \hypo{$\Delta,\sigma,\sigma,\Lambda\vdash\mathrm{ss}\xrightarrow{ss_\uparrow}{}\sigma',\Lambda'$}
    
    \infer1
    [{
      \begin{tabular}{@{}l}
        $\mathtt{clk}\in\mathrm{sl}$ \\
        $\Delta(\mathrm{id}_p)=\Lambda$ \\
      \end{tabular}
    }]
    {
      $\mathcal{D},\Delta,\sigma\vdash$
      \vhdle|process| \texttt{(}id$_p$\texttt{,} sl\texttt{,} vars\texttt{,} ss\texttt{)}
      $\xrightarrow{\uparrow}$
      $\sigma'$
    }
  \end{prooftree}
\end{table}

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{PsFENoClk}}
  
  \begin{prooftree}[template=\inserttext]
    \hypo{}

    \infer1
    [$\mathtt{clk}\notin\mathrm{sl}$]
    {
      $\mathcal{D},\Delta,\sigma
      \vdash$
      \vhdle|process| \texttt{(}id$_p$\texttt{,} sl\texttt{,} vars\texttt{,} ss\texttt{)}
      $\xrightarrow{\downarrow}\sigma$
    }
  \end{prooftree}
\end{table}

\begin{premises}
  The $\downarrow$ flag in the $ss_\downarrow$ relation indicates that
  $\mathtt{falling}$ blocks will be executed.
\end{premises}

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{PsFEClk}}
  
  \begin{prooftree}[template=\inserttext]

    \hypo{$\Delta,\sigma,\sigma,\Lambda\vdash\mathrm{ss}\xrightarrow{ss_\downarrow}{}\sigma',\Lambda'$}
    
    \infer1
    [{
      \begin{tabular}{@{}l}
        $\mathtt{clk}\in\mathrm{sl}$ \\
        $\Delta(\mathrm{id}_p)=\Lambda$ \\
      \end{tabular}
    }]
    {
      $\mathcal{D},\Delta,\sigma
      \vdash$
      \vhdle|process| \texttt{(}id$_p$\texttt{,} sl\texttt{,} vars\texttt{,} ss\texttt{)}
      $\xrightarrow{\downarrow}$
      $\sigma'$
    }
  \end{prooftree}
\end{table}

\subsubsection{Evaluation of a component instantiation statement}
\label{subsubsec:sync-comp-inst}

The following rules describe the evaluation of a component
instantiation statement during clock phases. These rules are similar
in every point to Rule~\textsc{CompRunInit} that describes the
evaluation of a component instantiation statement during the
initialization phase. The only difference lies in the execution of the
internal behavior of the component instance. During the clock phases,
the falling ($\xrightarrow{\downarrow}$) or the rising
($\xrightarrow{\uparrow}$) relations evaluate the internal behavior of
component instances.

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{CompRE}} \\
    {\begin{prooftree}[template=\inserttext]
        
        % Builds mapping for in ports.
        \hypo{$\Delta,\Delta_c,\sigma,\sigma_c\vdash\mathrm{i}\xrightarrow{mapip}\sigma'_c$}
        
        % Executes rising on component behavior.
        \infer[no rule]1{$\mathcal{D},\Delta_c,\sigma_c'\vdash{}\mathcal{D}(id_e).\mathrm{cs}\xrightarrow{\uparrow}\sigma_c''$}
        
        % Builds mapping for out ports.
        \infer[no rule]1{
          $\Delta,\Delta_c,\sigma,\sigma_c''\vdash$
          $\mathrm{o}$
          $\xrightarrow{mapop}$
          $\sigma'$
        }
        
        % Conclusion.
        \infer1
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $id_e\in\mathcal{D}$ \\
            $\Delta(\mathrm{id}_c)=\Delta_c$, $\sigma(\mathrm{id}_c)=\sigma_c$ \\
            $\sigma''={<}\mathcal{S}',\mathcal{C}'',\mathcal{E}'\cup(\mathcal{C}\dcap\mathcal{C}''){>}$ \\
            $\mathcal{C}''=\mathcal{C}'(\mathrm{id}_c)\leftarrow\sigma_c''$ \\
          \end{tabular}
        }]
        {
          $\mathcal{D},\Delta,\sigma\vdash$
          \vhdle|comp| (id$_c$, id$_e$, g, i, o)
          $\xrightarrow{\uparrow}{}\sigma''$
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{CompFE}} \\
    {\begin{prooftree}[template=\inserttext]
        
        % Builds mapping for in ports.
        \hypo{$\Delta,\Delta_c,\sigma,\sigma_c\vdash\mathrm{i}\xrightarrow{mapip}\sigma'_c$}
        
        % Executes rising on component behavior.
        \infer[no rule]1{$\mathcal{D},\Delta_c,\sigma_c'\vdash{}\mathcal{D}(id_e).\mathrm{cs}\xrightarrow{\downarrow}\sigma_c''$}
        
        % Builds mapping for out ports.
        \infer[no rule]1{
          $\Delta,\Delta_c,\sigma,\sigma_c''\vdash$
          $\mathrm{o}$
          $\xrightarrow{mapop}$
          $\sigma'$
        }
        
        % Conclusion.
        \infer1
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $id_e\in\mathcal{D}$ \\
            $\Delta(\mathrm{id}_c)=\Delta_c$, $\sigma(\mathrm{id}_c)=\sigma_c$ \\
            $\sigma''={<}\mathcal{S}',\mathcal{C}'',\mathcal{E}'\cup(\mathcal{C}\dcap\mathcal{C}''){>}$ \\
            $\mathcal{C}''=\mathcal{C}'(\mathrm{id}_c)\leftarrow\sigma_c''$ \\
          \end{tabular}
        }]
        {
          $\mathcal{D},\Delta,\sigma\vdash$
          \vhdle|comp| (id$_c$, id$_e$, g, i, o)
          $\xrightarrow{\downarrow}{}\sigma''$
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Evaluation of the composition of concurrent statements}
\label{subsubsec:comp-of-cs-clk}

The following rules describe the evaluation of the composition of
concurrent statements and the evaluation of null statements during the
clock phases. These rules are similar to the ones describe for the
initialization phase. Thus, the reader can refer to
Section~\ref{subsubsec:ps-stmt-init} for more details.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{ParFE}} \\
    {\begin{prooftree}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{\downarrow}\sigma'}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs'}\xrightarrow{\downarrow}\sigma''}
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l@{}}
            $\mathcal{E}'\cap\mathcal{E}''=\emptyset$ \\
          \end{tabular}
        }] {
          \mathcal{D},\Delta,\sigma\vdash\mathrm{cs}~\mathtt{||}~\mathrm{cs'}\xrightarrow{\downarrow}
          \mathtt{merge}(\sigma,\sigma',\sigma'')
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{NullFE}} \\
    {\begin{prooftree}
        \infer0
        {
          \Delta,\sigma\vdash\mathtt{null}\xrightarrow{\downarrow}\sigma
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{ParRE}} \\
    {\begin{prooftree}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{\uparrow}\sigma'}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs'}\xrightarrow{\uparrow}\sigma''}
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l@{}}
            $\mathcal{E}'\cap\mathcal{E}''=\emptyset$ \\
          \end{tabular}
        }] {
          \mathcal{D},\Delta,\sigma\vdash\mathrm{cs}~\mathtt{||}~\mathrm{cs'}\xrightarrow{\uparrow}
          \mathtt{merge}(\sigma,\sigma',\sigma'')
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{NullRE}} \\
    {\begin{prooftree}
        \infer0
        {\Delta,\sigma\vdash\mathtt{null}\xrightarrow{\uparrow}\sigma}
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsection{Stabilization rules}
\label{sec:stab-rules}

The following rules describe the evaluation of concurrent statements,
representing a design's behavior, during a stabilization phase. The
stabilization phase triggers the execution of the combinational parts
of the behavior by appealing to the $comb$ relation.  When the
execution of the combinational parts of the behavior does not change
the design state anymore, then we have reached a stable state and the
stabilization phase ends (Rule~\textsc{StabilizeEnd}). When the
execution of the combinational parts produces some events, i.e. it
changes the value of signals or the internal state of component
instances, then the stabilization phase must continue until a stable
state is reached (Rule~\textsc{StabilizeLoop}).

\begin{sideconds}
  \begin{itemize}
  \item In Rule~\textsc{StabilizeEnd}, state $\sigma$ is an eventless
    state, i.e. its event set $\mathcal{E}$ is empty.
  \item In Rule~\textsc{StabilizeLoop}, state $\sigma'$ is an eventful
    state and state $\sigma''$ is eventless.
\end{itemize}
\end{sideconds}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{StabilizeEnd}} \\
    
    {\begin{prooftree}[template=\inserttext]

        \hypo{$\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{comb}\sigma$}
        \infer1
        [$\mathcal{E}=\emptyset$]
        {
          $\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{\rightsquigarrow}\sigma$
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{StabilizeLoop}} \\
    {\begin{prooftree}[template=\inserttext]
        \hypo{$\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{comb}\sigma'$}
        \hypo{$\mathcal{D},\Delta,\sigma'\vdash\mathrm{cs}\xrightarrow{\rightsquigarrow}\sigma''$}
        \infer2
        [{
          \begin{tabular}{@{}l}
            $\mathcal{E}\neq\emptyset$ \\
            $\mathcal{E}''=\emptyset$
          \end{tabular}
        }]
        {
          $\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{\rightsquigarrow}\sigma''$
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Evaluation of a process statement}

Rule~\textsc{PsComb} describes the execution of a process statement
during a stabilization phase. Even synchronous processes can be
executed during a stabilization phase, however, the falling and rising
blocks are not interpreted. Thus, the evaluation of a \emph{purely}
synchronous process, defined only with falling or rising blocks and no
combinational parts, does not change the design state during a
stabilization phase. 

\begin{premises}
  \begin{itemize}
  \item The $c$ flag (for \textit{combinational}) on the $ss_c$
    relation indicates that instructions responding to clock events
    (\texttt{falling} and \texttt{rising} blocks) and instructions
    executed during the initialization phase only (\texttt{rst}
    blocks) will not be considered.

  \item The set of events of state $\sigma$ is emptied
    ($NoEv(\sigma)$, see Notation~\ref{notation:noev}) before the
    evaluation of the process statement body. It corresponds to the
    consumption of the information brought by the event set. Once the
    information has been consumed, new events can be generated by
    executing the process body.
  \end{itemize}
\end{premises}

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{PsComb}}
  
  \begin{prooftree}[template=\inserttext]
    
    % Executes ss.
    \hypo{$\Delta,\sigma,NoEv(\sigma),\Lambda\vdash\mathrm{ss}\xrightarrow{ss_c}{}\sigma',\Lambda'$}

    % Conclusion.
    \infer1
    [{
      \begin{tabular}{@{}l}
        $\Delta(\mathrm{id}_p)=\Lambda$ \\
      \end{tabular}
    }]
    {
      $\mathcal{D},\Delta,\sigma\vdash$
      \vhdle|process| \texttt{(}id$_p$\texttt{,} sl\texttt{,} vars\texttt{,} ss\texttt{)}
      $\xrightarrow{comb}\sigma'$
    }
  \end{prooftree}
\end{table}

\subsubsection{Evaluation of a component instantiation statement}

Rule~\textsc{CompComb} describes the evaluation of a component
instantiation statement during a stabilization phase. This rule is
similar in every point to Rule~\textsc{CompRunInit}, and
Rules~\textsc{CompRE} and \textsc{CompFE}, that describe the
evaluation of a component instantiation statement during the
initialization phase, and the clock phases. The only difference lies
in the execution of the internal behavior of the component
instance. During a stabilization, the $comb$ relation evaluate the
internal behavior of component instances. Otherwise, see
Section~\ref{subsubsec:ci-stmt-init} for more details about the
premises and side conditions of Rule~\textsc{CompComb}.

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{CompComb}} \\
    {\begin{prooftree}[template=\inserttext]
        
        % Builds mapping for in ports.
        \hypo{$\Delta,\Delta_c,\sigma,\sigma_c\vdash\mathrm{i}\xrightarrow{mapip}\sigma'_c$}
        
        % Executes comb on component behavior.
        \infer[no rule]1{$\mathcal{D},\Delta_c,\sigma_c'\vdash{}\mathcal{D}(id_e).\mathrm{cs}\xrightarrow{comb}\sigma_c''$}
        
        % Builds mapping for out ports.
        \infer[no rule]1{
          $\Delta,\Delta_c,NoEv(\sigma),\sigma_c''\vdash$
          $\mathrm{o}$
          $\xrightarrow{mapop}$
          $\sigma'$
        }
        
        % Conclusion.
        \infer1
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $id_e\in\mathcal{D}$ \\
            $\Delta(\mathrm{id}_c)=\Delta_c$, $\sigma(\mathrm{id}_c)=\sigma_c$ \\
            $\sigma''={<}\mathcal{S}',\mathcal{C}'',\mathcal{E}'\cup(\mathcal{C}\dcap\mathcal{C}''){>}$ \\
            $\mathcal{C}''=\mathcal{C}'(\mathrm{id}_c)\leftarrow\sigma_c''$ \\
          \end{tabular}
        }]
        {
          $\mathcal{D},\Delta,\sigma\vdash$
          \vhdle|comp| (id$_c$, id$_e$, g, i, o)
          $\xrightarrow{comb}$
          $\sigma''$
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Evaluation of the composition of concurrent statements}

The following rules describe the evaluation of the composition of
concurrent statements and the evaluation of null statements during a
stabilization phase. These rules are similar to the ones describe for
the initialization phase. Thus, the reader can refer to
Section~\ref{subsubsec:ps-stmt-init} for more details.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{ParComb}} \\
    {\begin{prooftree}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs}\xrightarrow{comb}\sigma'}
        \hypo{\mathcal{D},\Delta,\sigma\vdash\mathrm{cs'}\xrightarrow{comb}\sigma''}
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l@{}}
            $\mathcal{E}'\cap\mathcal{E}''=\emptyset$ \\
          \end{tabular}
        }] {
          \mathcal{D},\Delta,\sigma\vdash\mathrm{cs}~\mathtt{||}~\mathrm{cs'}\xrightarrow{comb}
          \mathtt{merge}(\sigma,\sigma',\sigma'')
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{NullComb}} \\
    {\begin{prooftree}
        \infer0
        {
          \Delta,\sigma\vdash\mathtt{null}\xrightarrow{comb}NoEv(\sigma)
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsection{Evaluation of input and output port maps}
\label{subsec:mapinout}

\subsubsection{Evaluation of an input port map}
\label{sec:ipmap-eval}

Here, we define the $mapip$ relation that evaluates the input port map
of a component instance. For each association of the input port map,
the actual part is evaluated and the result is assigned to the formal
part of the association, i.e. an input port
(Rule~\textsc{MapipSimple}) or an indexed input port
(Rule~\textsc{MapipPartial}) identifier.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapipSimple}} \\
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma\vdash\mathrm{e}\xrightarrow{e}v}

        % Checks that v complies with T.
        \hypo{v\in_c{}T}

        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\Delta_c(\mathrm{id}_s)=T$ \\
            $\sigma_c={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'=\mathcal{S}(id_s)\leftarrow{}v$ \\
          \end{tabular}
        }]
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_s\Rightarrow\mathrm{e}
          \xrightarrow{mapip}
          {<}\mathcal{S}',\mathcal{C},\mathcal{E}{>}
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapipPartial}} \\
    {\begin{prooftree}

        % Evaluates e_i and e.
        \hypo{\Delta,\sigma&\vdash\mathrm{e}\xrightarrow{e}v}
        \infer[no rule]1{&\vdash\mathrm{e}_i\xrightarrow{e}v_i}        

        % Checks that v complies with T.
        \hypo{v&\in_c{}T}
        \infer[no rule]1{v_i&\in_c{}nat(n,m)}

        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\Delta_c(\mathrm{id}_s)=array(T,n,m)$ \\
            $\sigma_c={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'=\mathcal{S}(id_s)\leftarrow\mathtt{set\_at}(v,v_i,\mathcal{S}(id_s))$ \\
          \end{tabular}
        }]
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_s(\mathrm{e}_i)\Rightarrow\mathrm{e}
          \xrightarrow{mapip}
          {<}\mathcal{S}',\mathcal{C},\mathcal{E}{>}
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{MapipComp}}
  
  \begin{prooftree}    
    % Evaluates mapip on assoc_p.
    \hypo{
      \Delta,\Delta_c,\sigma,\sigma_c\vdash
      \mathrm{assoc}_{ip} 
      \xrightarrow{mapip}
      \sigma'_c
    }

    % Evaluates mapip on portmap.
    \hypo{
      \Delta,\Delta_c,\sigma,\sigma'_c\vdash
      \mathrm{ipmap}
      \xrightarrow{mapip}
      \sigma''_c
    }

    % Conclusion.
    \infer2
    {
      \Delta,\Delta_c,\sigma,\sigma_c\vdash
      \langle{}\mathrm{assoc}_{ip},~\mathrm{ipmap}\rangle
      \xrightarrow{mapip}
      \sigma''_c
    }
  \end{prooftree}
\end{table}

\subsubsection{Evaluation of an output port map}
\label{sec:opmap-eval}

Here, we define the $mapop$ relation that evaluates the output port
map of a component instance. For each association of the output port
map, the formal part is evaluated and the result is assigned to the
actual part of the association. There can be five kind of associations
in an output port map:

\begin{itemize}
\item an output port identifier (of the component instance) is
  associated with the \texttt{open} keyword, thus denoting an
  unconnected output port in the output interface of the component
  instance
\item an output port identifier is associated with an internal signal
  or an output port identifier of the embedding design
  (Rule~\textsc{MapopSimpleToSimple})
\item an output port identifier is associated with an indexed internal
  signal or an output port identifier of the embedding design
  (Rule~\textsc{MapopSimpleToPartial})
\item an indexed output port identifier is associated with an internal
  signal or an output port identifier of the embedding design
  (Rule~\textsc{MapopPartialToSimple})
\item an indexed output port identifier is associated with an indexed
  internal signal or an output port identifier of the embedding design
  (Rule~\textsc{MapopPartialToPartial})
\end{itemize}

\begin{remark}[Out ports and $e$]
  We can not use the $e$ relation to interpret the values of output
  ports, because output ports are write-only constructs. We append the
  flag $o$ to the $e$ relation (i.e, $e_o$) to enable the evaluation
  of output port identifiers as regular signal identifier expressions.
\end{remark}

The $e_o$ relation is only defined to retrieve the value of out
ports from a store signal $\mathcal{S}$ under a design state
$\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$.

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{OutO}} \\
    {\begin{prooftree}
        \infer0
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_s\in{}Outs(\Delta)$ \\
            $\mathrm{id}_s\in\sigma$ \\
          \end{tabular}
        }] {
          \Delta,\sigma\vdash
          \mathrm{id}_s
          \xrightarrow{e_o}
          \sigma(\mathrm{id}_s)
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IdxOutO}} \\
    {\begin{prooftree}

        % Evaluates e_i.
        \hypo{
          \vdash
          \mathrm{e}_i
          \xrightarrow{e}
          v_i
        }

        % Checks well-typed v_i.
        \hypo{v_i\in_c{}nat(n,m)}
        
        % Conclusion.
        \infer2
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_s\in{}Outs(\Delta)$ \\
            $\mathrm{id}_s\in\sigma$ \\
            $\Delta(\mathrm{id}_s)={}array(T,n,m\mathtt{)}$ \\
            $i=v_i~\mathtt{mod}~n$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma\vdash
          \mathrm{id}_s(\mathrm{e}_i)
          \xrightarrow{e_o}
          \mathtt{get\_at}(i,\sigma(\mathrm{id}_s))
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

The following rules define the $mapop$ relation.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapopOpen}} \\
    {\begin{prooftree}

        % Conclusion
        \infer
        0
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_f\Rightarrow\mathtt{open}
          \xrightarrow{mapop}
          \sigma
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{sideconds}
  In the signal store $\mathcal{S}'$, value $v$ is assigned to the
  signal identifier $\mathrm{id}_a$. If this assignment changes the
  value of $\mathrm{id}_a$, then an event on signal $\mathrm{id}_a$
  must be registered.  The expression
  $\mathcal{E}\cup\mathcal{S}\dcap\mathcal{S}'$ represents the set of
  signals that have a different value in signal store $\mathcal{S}$
  and $\mathcal{S}'$.
\end{sideconds}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapopSimpleToSimple}} \\
    {\begin{prooftree}

        % Evaluates name.
        \hypo{\Delta_c,\sigma_c\vdash\mathrm{id}_f\xrightarrow{e_o}v}

        % Checks that v complies with T.
        \hypo{v\in_c{}T}
        
        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_a\in{}Sigs(\Delta)\cup{}Outs(\Delta)$ \\
            $\Delta(\mathrm{id}_a)=T$ \\
            $\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'=\mathcal{S}(id_a)\leftarrow{}v$, $\mathcal{E}'=\mathcal{E}\cup(\mathcal{S}\dcap\mathcal{S}')$ \\
          \end{tabular}
        }]
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_f\Rightarrow\mathrm{id}_a
          \xrightarrow{mapop}
          {<}\mathcal{S}',\mathcal{C},\mathcal{E}'{>}
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapopSimpleToPartial}} \\
    {\begin{prooftree}

        % Evaluates id_f and e_i.
        \hypo{&\vdash\mathrm{e}_i\xrightarrow{e}v_i}
        \infer[no rule]1{&\Delta_c,\sigma_c\vdash\mathrm{id}_f\xrightarrow{e_o}v}

        % Checks that v complies with T.
        \hypo{v&\in_c{}T}
        \infer[no rule]1{v_i&\in_c{}{}nat(n,m)}

        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{l}
            $\mathrm{id}_a\in{}Sigs(\Delta)\cup{}Outs(\Delta)$ \\
            $\Delta(\mathrm{id}_a)={}array(T,n,m\mathtt{)}$ \\
            $\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'=\mathcal{S}(id_a)\leftarrow\mathtt{set\_at}(v,v_i,\mathcal{S}(id_a))$ \\
            $\mathcal{E}'=\mathcal{E}\cup(\mathcal{S}\dcap\mathcal{S}')$ \\
          \end{tabular}
        }]
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_f\Rightarrow\mathrm{id}_a(\mathrm{e}_i)
          \xrightarrow{mapop}
          {<}\mathcal{S}',\mathcal{C},\mathcal{E}'{>}
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapopPartialToSimple}} \\
    {\begin{prooftree}

        % Evaluates name.
        \hypo{\Delta_c,\sigma_c\vdash\mathrm{id}_f(\mathrm{e}'_i)\xrightarrow{e_o}v}

        % Checks that v complies with T.
        \hypo{v\in_c{}T}
        
        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_a\in{}Sigs(\Delta)\cup{}Outs(\Delta)$ \\
            $\Delta(\mathrm{id}_a)=T$ \\
            $\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'=\mathcal{S}(id_a)\leftarrow{}v$, $\mathcal{E}'=\mathcal{E}\cup(\mathcal{S}\dcap\mathcal{S}')$ \\
          \end{tabular}
        }]
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_f(\mathrm{e}'_i)\Rightarrow\mathrm{id}_a
          \xrightarrow{mapop}
          {<}\mathcal{S}',\mathcal{C},\mathcal{E}'{>}
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{MapopPartialToPartial}} \\
    {\begin{prooftree}

        % Evaluates id_f and e_i.
        \hypo{&\vdash\mathrm{e}_i\xrightarrow{e}v_i}
        \infer[no rule]1{&\Delta_c,\sigma_c\vdash\mathrm{id}_f(\mathrm{e}'_i)\xrightarrow{e_o}v}

        % Checks that v complies with T.
        \hypo{v&\in_c{}T}
        \infer[no rule]1{v_i&\in_c{}{}nat(n,m)}

        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{l}
            $\mathrm{id}_a\in{}Sigs(\Delta)\cup{}Outs(\Delta)$ \\
            $\Delta(\mathrm{id}_a)={}array(T,n,m\mathtt{)}$ \\
            $\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'=\mathcal{S}(id_a)\leftarrow\mathtt{set\_at}(v,v_i,\mathcal{S}(id_a))$ \\
            $\mathcal{E}'=\mathcal{E}\cup(\mathcal{S}\dcap\mathcal{S}')$ \\
          \end{tabular}
        }]
        {
          \Delta,\Delta_c,\sigma,\sigma_c\vdash
          \mathrm{id}_f(\mathrm{e}'_i)\Rightarrow\mathrm{id}_a(\mathrm{e}_i)
          \xrightarrow{mapop}
          {<}\mathcal{S}',\mathcal{C},\mathcal{E}'{>}
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}


\begin{table}[H]
  {\fontsize{10}{13}\selectfont\textsc{MapopComp}}
  
  \begin{prooftree}    
    % Evaluates mapip on assoc.
    \hypo{\Delta,\Delta_c,\sigma,\sigma_c\vdash\mathrm{assoc}_{po}\xrightarrow{mapop}\sigma'}

    % Evaluates mapip on portmap.
    \hypo{\Delta,\Delta_c,\sigma',\sigma_c\vdash\mathrm{opmap}\xrightarrow{mapop}\sigma''}

    % Conclusion.
    \infer2
    {
      \Delta,\Delta_c,\sigma,\sigma_c\vdash
      \langle{}\mathrm{assoc}_{po},~\mathrm{opmap}\rangle
      \xrightarrow{mapop}\sigma''
    }
  \end{prooftree}
\end{table}



\subsection{Evaluation of sequential statements}
\label{subsec:seq-stmts}

Here, we define the $ss$ relation that evaluates the sequential
statements used in the body of processes. The phases of a simulation
cycle influences the evaluation of sequential statements. For
instance, reset blocks are only evaluated during an initialization
phase, falling blocks during a falling edge phase\dots Thus, we append
a specific flag to the $ss$ relation to enable the evaluation of
specific sequential statements at particular phases of the simulation
cycle. There are four different flags, the $c$ flag to denote the
execution of combinational statements only, the $i$ flag to enable the
execution of reset blocks, the $\uparrow$ (resp. $\downarrow$) flag to
enable the execution of rising (resp. falling) blocks.  Writing the
$ss$ relation with no flag indicates that the evaluation of a given
sequential statement is the same for every phase of the simulation
cycle. A flag is tranferred from the conclusion to the premises when
an sequential statement is composed of inner sequential blocks.

\subsubsection{Signal assigment statement} A signal assignment
generates a new design state with a modified signal store and a new
set of events. Note that there are two states on the left side of the
thesis symbol. $\sigma$ represents the state holding the current
values of signals, and $\sigma_w$ holds the new values of signals
(i.e. the \emph{written} state).

\begin{sideconds}
  The expression $\mathcal{S}\dcap\mathcal{S}'_w$ registers signal
  $\mathrm{id}_s$ as an eventful signal if its value after assignment,
  i.e. in the signal store $\mathcal{S}'_w$, is different from its
  current value at state $\sigma$, i.e. in the signal store
  $\mathcal{S}$.
\end{sideconds}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{SigAssign}} \\
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}v}
        
        % Checks that v complies with T.
        \hypo{v\in_c{}T}
        
        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_s\in{}Sigs(\Delta)\cup{}Outs(\Delta)$ \\
            $\Delta(\mathrm{id}_s)=T$ \\
            % $\sigma={<}\mathcal{S},\mathcal{C},\mathcal{E}{>}$ \\
            $\mathcal{S}'_w=\mathcal{S}_w(id_s)\leftarrow{}v$ \\
            $\mathcal{E}'_w=\mathcal{E}_w\cup(\mathcal{S}\dcap\mathcal{S}'_w)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash
          \mathrm{id}_s\Leftarrow\mathrm{e}
          \xrightarrow{ss}
          {<}\mathcal{S}'_w,\mathcal{C}_w,\mathcal{E}'_w{>},\Lambda
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IdxSigAssign}} \\
    {\begin{prooftree}

        % Evaluates e_i and e.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}_i\xrightarrow{e}v_i}
        \infer[no rule]1{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}

        % Checks that v complies with T.

        \hypo{v&\in_c{}T}
        \infer[no rule]1{v_i&\in_c{}nat(n,m)}
        
        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_s\in{}Sigs(\Delta)\cup{}Outs(\Delta)$ \\
            $\Delta(\mathrm{id}_s)={}array(T,n,m\mathtt{)}$ \\
            $\mathcal{S}'_w=\mathcal{S}_w(id_s)\leftarrow\mathtt{set\_at}(v,v_i,\mathcal{S}_w(id_s))$ \\
            $\mathcal{E}'_w=\mathcal{E}_w\cup(\mathcal{S}\dcap\mathcal{S}'_w)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash
          \mathrm{id}_s(\mathrm{e}_i)\Leftarrow\mathrm{e}
          \xrightarrow{ss}
          {<}\mathcal{S}'_w,\mathcal{C}_w,\mathcal{E}'_w{>},\Lambda
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Variable assignment statement}

A variable assignment statement modifies the value of a variable
defined in a local environment $\Lambda$.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{VarAssign}} \\    
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}v}

        % Checks that v complies with T.
        \hypo{v\in_c{}T}

        % Conclusion.
        \infer2
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\in\Lambda$ \\
            $\Lambda(\mathrm{id}_v)=(T,val)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash
          \mathrm{id}_v:=\mathrm{e}
          \xrightarrow{ss}
          \sigma_w,\Lambda(id_v)\leftarrow{}(T,v)
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IdxVarAssign}} \\    
    {\begin{prooftree}

        % Evaluates e_i.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}_i\xrightarrow{e}v_i}
        \infer[no rule]1{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}

        % Checks that v complies with T.
        \hypo{v_i&\in_c{}nat(n,m)}
        \infer[no rule]1{v&\in_c{}T}

        % Conclusion.
        \infer2
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\in\Lambda$ \\
            $\Lambda(\mathrm{id}_v)=({}array(T,n,m\mathtt{)},val)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash
          \mathrm{id}_v(\mathrm{e}_i):=\mathrm{e}
          \xrightarrow{ss}
          \sigma_w,\Lambda(id_v)\leftarrow{}(T,\mathtt{set\_at}(v,v_i,val))
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{remark}[Local variables and persistent values]
  In the LRM, the value of local variables is persistent through the
  multiple execution of a process. However, in the definition of the
  place and transition designs, and in the VHDL programs generated by
  \hilecop{}, all local variables are initialized by an assignment
  statement at the beginning of the body of processes. Thus, to
  simplify the \hvhdl{} semantics, we choose not to consider local
  variables as persistent memory as their values are renewed at each
  execution of a process.
\end{remark}

\subsubsection{If statement}
\label{subsubsec:if-stmt}

Here, we present the classical evaluation of if and if-else
statements.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{If}$\top$} \\    
    {\begin{prooftree}

        % Evaluates condition.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}\top}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\xrightarrow{ss}\sigma'_w,\Lambda'}

        % Conclusion.
        \infer2
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|if|$~(\mathrm{e})~\mathrm{ss}
          \xrightarrow{ss}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{If}$\bot$} \\
    {\begin{prooftree}

        % Evaluates condition.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}\bot}

        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|if|$~(\mathrm{e})~\mathrm{ss}
          \xrightarrow{ss}
          \sigma_w,\Lambda
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IfElse}$\top$} \\    
    {\begin{prooftree}

        % Evaluates condition.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{expr}\top}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\xrightarrow{ss}\sigma'_w,\Lambda'}

        % Conclusion.
        \infer2
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|if|$~(\mathrm{e})~\mathrm{ss}~\mathrm{ss}'
          \xrightarrow{ss}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IfElse}$\bot$} \\  
    {\begin{prooftree}

        % Evaluates condition.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}\bot}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}'\xrightarrow{ss}\sigma'_w,\Lambda'}

        % Conclusion.
        \infer2
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|if|$~(\mathrm{e})~\mathrm{ss}~\mathrm{ss}'
          \xrightarrow{ss}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Loop statement}

Here, we present the classical evaluation of for-loop statements.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{Loop}$\bot$} \\
    {\begin{prooftree}

        % Evaluates upper bound check.
        \hypo{\Delta,\sigma,\Lambda_i\vdash\mathrm{id}_v=\mathrm{e}'\xrightarrow{e}\bot}

        % Evaluates ss and recursive call.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda_i&\vdash\mathrm{ss}\xrightarrow{ss}\sigma'_w,\Lambda'}
        \infer[no rule]1{
          \Delta,\sigma,\sigma'_w,\Lambda'&\vdash~
          $\vhdle|for|$~(\mathrm{id}_v,\mathrm{e},\mathrm{e}')~\mathrm{ss}
          \xrightarrow{ss}\sigma''_w,\Lambda''
        }
        
        % Conclusion. 
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\in\Lambda$ \\
            $\Lambda(\mathrm{id}_v)=(T,val)$ \\
            $\Lambda_i=\Lambda(id_v)\leftarrow{}(T,val+1)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|for|$~(\mathrm{id}_v,\mathrm{e},\mathrm{e}')~\mathrm{ss}
          \xrightarrow{ss}
          \sigma''_w,\Lambda''
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{Loop}$\top$} \\    
    {\begin{prooftree}
                
        % Upper bound check true.
        \hypo{\Delta,\sigma,\Lambda_i\vdash\mathrm{id}_v=\mathrm{e}'\xrightarrow{e}\top}

        % Conclusion.
        \infer1
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\in\Lambda$ \\
            $\Lambda(\mathrm{id}_v)=(T,val)$ \\
            $\Lambda_i=\Lambda(id_v)\leftarrow(T,val+1)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|for|$~(\mathrm{id}_v,\mathrm{e},\mathrm{e}')~\mathrm{ss}
          \xrightarrow{ss}
          \sigma_w,\Lambda\setminus(id_v,\Lambda(id_v))
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{LoopInit}} \\
    {\begin{prooftree}
        
        % Evaluates e and e'.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}
        \infer[no rule]1{\Delta,\sigma,\Lambda&\vdash\mathrm{e'}\xrightarrow{e}v'}
        
        % Upper bound check true.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda_i\vdash~
          $\vhdle|for|$~(\mathrm{id}_v,\mathrm{e},\mathrm{e}')~\mathrm{ss}
          \xrightarrow{ss}
          \sigma'_w,\Lambda'}

        % Conclusion.
        \infer2
        [{\renewcommand{\arraystretch}{1.5}
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\notin\Lambda$ \\
            $\Lambda_i=\Lambda\cup(id_v,({}nat(v,v'),v))$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|for|$~(\mathrm{id}_v,\mathrm{e},\mathrm{e}')~\mathrm{ss}
          \xrightarrow{ss}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Rising and falling edge block statements}
\label{subsubsec:rise-and-fall-stmts}

Here, we define the execution of rising and falling blocks. Rising
(resp. Falling) blocks are executed only during a rising
(resp. falling) edge phase of a simulation cycle, i.e. when the flag
$\uparrow$ (resp. $\downarrow$) is raised
(Rule~$\textsc{RisingEgdeExec}$ and
\textsc{FallingEdgeExec}). Otherwise, the evaluation of these blocks
is without effect on state $\sigma_w$ and on the local environment
$\Lambda$ (Rules~\textsc{RisingEdgeDefault} and
\textsc{FallingEdgeDefault}).

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{RisingEdgeDefault}} \\    
    {\begin{prooftree}
        
        % Conclusion.
        \infer0
        [$f\neq\uparrow$]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|rising|$~\mathrm{ss}
          \xrightarrow{ss_f}
          \sigma_w,\Lambda
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{FallingEdgeDefault}} \\    
    {\begin{prooftree}
        
        % Conclusion.
        \infer0
        [$f\neq\downarrow$]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|falling|$~\mathrm{ss}
          \xrightarrow{ss_f}
          \sigma_w,\Lambda
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{RisingEdgeExec}} \\    
    {\begin{prooftree}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\xrightarrow{ss_\uparrow}\sigma'_w,\Lambda'}
        
        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|rising|$~\mathrm{ss}
          \xrightarrow{ss_\uparrow}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{FallingEdgeExec}} \\    
    {\begin{prooftree}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\xrightarrow{ss_\downarrow}\sigma'_w,\Lambda'}
        
        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|falling|$~\mathrm{ss}
          \xrightarrow{ss_\downarrow}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Rst block statement}

Here, we define the evaluation of reset blocks. The first part of
reset blocks is only evaluated during the initialization phase of a
simulation cycle, i.e. when the $i$ flag is raised
(Rule~\textsc{RstExec}). Otherwise, it is the second part of the reset
block that is evaluated (Rule~\textsc{RstDefault}). Remember that a
reset block is the transcription of a if-else statement specifically
devised for the \hvhdl{} abstract syntax.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{RstDefault}} \\    
    {\begin{prooftree}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss'}\xrightarrow{ss_f}\sigma'_w,\Lambda'}
        
        % Conclusion.
        \infer1
        [$f\neq{}i$]
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|rst|$~\mathrm{ss}~\mathrm{ss'}
          \xrightarrow{ss_f}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{RstExec}} \\    
    {\begin{prooftree}

        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\xrightarrow{ss_i}\sigma'_w,\Lambda'}
        
        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\sigma_w,\Lambda\vdash~
          $\vhdle|rst|$~\mathrm{ss}~\mathrm{ss'}
          \xrightarrow{ss_i}
          \sigma'_w,\Lambda'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsubsection{Composition of sequential statements and null statement}

Here, we present the evaluation of the composition of sequential
statements (Rule~\textsc{SeqStmt}) and of the null sequential
statement (Rule~\textsc{NullStmt}). When evaluating a sequence of
statements, the same state $\sigma$ holding the current value of
signals is used to execute both part of the sequence. The written
state $\sigma_w$ is modified by the first part of the sequence, thus
resulting in a state $\sigma'_w$. Then, $\sigma'_w$ is used to
evaluate the second part of the sequence.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{SeqStmt}} \\
    {\begin{prooftree}
        
        % Evaluates ss.
        \hypo{\Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\xrightarrow{ss}\sigma'_w,\Lambda'}

        % Evaluates ss'.
        \hypo{\Delta,\sigma,\sigma'_w,\Lambda'\vdash\mathrm{ss'}\xrightarrow{ss}\sigma''_w,\Lambda''}

        % Conclusion.
        \infer2{
          \Delta,\sigma,\sigma_w,\Lambda\vdash\mathrm{ss}\mathtt{;}~\mathrm{ss}'\xrightarrow{ss}\sigma''_w,\Lambda''
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{NullStmt}} \\
    {\begin{prooftree}        

        % Conclusion.
        \infer0{
          \Delta,\sigma,\sigma_w,\Lambda\vdash\mathtt{null}\xrightarrow{ss}\sigma_w,\Lambda
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\subsection{Evaluation of expressions}
\label{subsec:expr-rules}

Here, we present the evaluation of expressions used throughout the
definition of \hvhdl{} designs. Rules~\textsc{Nat}, \textsc{False} and
\textsc{True} describe the evaluation of natural number and boolean
constants. Rule~\textsc{Aggreg} describes the evaluation of an
aggregate expression. Rule~\textsc{Gen} presents the evaluation of a
generic constant identifier. Rules~\textsc{Sig} and \textsc{Var}
describe the evaluation of signal and variable identifiers.
Rules~\textsc{IdxSig} and \textsc{IdxVar} corresponds to the
evaluation of indexed signal and indexed variable identifiers.

% Nat and Bool literals.

\begin{table}[H]
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{Nat}} \\
    {\begin{prooftree}
        \infer0
        [{
          \begin{tabular}{@{}l}
            $\mathrm{n}\in\mathbb{N}$ \\
            $\mathrm{n}\le\mathtt{NATMAX}$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{n}\xrightarrow{e}n
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{False}} \\
    {\begin{prooftree}
        \infer0
        {
          \Delta,\sigma,\Lambda\vdash\mathtt{false}\xrightarrow{e}\bot
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{True}} \\
    {\begin{prooftree}
        \infer0
        {
          \Delta,\sigma,\Lambda\vdash\mathtt{true}\xrightarrow{e}\top
        }
      \end{prooftree}} \\
  \end{tabular}

\end{table}

% Aggregate.

\begin{table}[H]
  \centering
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{Aggreg}} \\
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}_i\xrightarrow{e}v_i}

        % Conclusion.
        \infer1
        [$i=1,\dots,n$]
        {
          \Delta,\sigma,\Lambda\vdash\mathtt{(}\mathrm{e}_1,\dots,\mathrm{e}_n\mathtt{)}\xrightarrow{e}(v_1,\dots,v_n)
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

% Name expressions.

\begin{table}[H]
  \centering
  \begin{tabular}{l}
    {\fontsize{10}{13}\selectfont\textsc{Sig}} \\
    {\begin{prooftree}
        \infer0
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_s\in{}Sigs(\Delta)\cup{}Ins(\Delta)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{id}_s\xrightarrow{e}\sigma(\mathrm{id}_s)
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{Var}} \\
    {\begin{prooftree}
        \infer0
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\in\Lambda$ \\
            $\Lambda(\mathrm{id}_v)=(T,v)$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{id}_v\xrightarrow{e}v
        }
      \end{prooftree}} \\
    \end{tabular}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{Gen}} \\
    {\begin{prooftree}
      \infer0
      [{
        \begin{tabular}{@{}l}
          $\mathrm{id}_g\in{}Gens(\Delta)$ \\
          $\Delta(\mathrm{id}_g)=(T,v)$ \\
        \end{tabular}
      }]
      {
        \Delta,\sigma,\Lambda\vdash\mathrm{id}_g\xrightarrow{e}v
      }
    \end{prooftree}} \\
  \end{tabular}
  % Idx name expressions.
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IdxSig}} \\
    {\begin{prooftree}

        % Evaluates e_i.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}_i\xrightarrow{e}v_i}

        % Well-typed v_i.
        \hypo{v_i\in_c{}{}nat(n,m)}
        
        % Conclusion.
        \infer2
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_s\in{}Sigs(\Delta)\cup{}Ins(\Delta)$ \\
            $\Delta(\mathrm{id}_s)={}array(T,n,m\mathtt{)}$ \\
            $i=v_i~\mathtt{mod}~n$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\Lambda\vdash
          \mathrm{id}_s(\mathrm{e}_i)
          \xrightarrow{e}
          \mathtt{get\_at}(i,\sigma(\mathrm{id}_s))
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{IdxVar}} \\
    {\begin{prooftree}
        
        % Evaluates e_i.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}_i\xrightarrow{e}v_i}

        % Well-typed v_i.
        \hypo{v_i\in_c{}{}nat(n,m)}
        
        % Conclusion.
        \infer2
        [{
          \begin{tabular}{@{}l}
            $\mathrm{id}_v\in\Lambda$ \\
            $\Lambda(\mathrm{id}_v)=({}array(T,n,m\mathtt{)},v)$ \\
            $i=v_i~\mathtt{mod}~n$ \\
          \end{tabular}
        }]
        {
          \Delta,\sigma,\Lambda\vdash
          \mathrm{id}_v(\mathrm{e}_i)
          \xrightarrow{e}
          \mathtt{get\_at}(i,v)
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

In Rules~\textsc{IdxSig} and \textsc{IdxVar}, \texttt{get\_at}$(i,a)$
is a function returning the $i$-th element of array $a$.

Rule~\textsc{NatAdd} describe the evaluation of the addition between
two expressions of the natural type. The operator $+_\mathbb{N}$
denotes the addition operator of natural numbers in the semantic
world. We add as a side condition that the result of the addition
between two natural numbers must not exceed the value of the
\texttt{NATMAX} number (the greatest natural number representable in
\hvhdl{}). Rule~\textsc{NatSub} describes the evaluation of the
substraction between two expressions of the natural
type. Rule~\textsc{OrdOp} describes the evaluation of the comparison
between two expressions of the natural types. The result of the
comparison is a Boolean value. Rules~\textsc{BoolBinOp} and
\textsc{NotOp} describes the evaluation of Boolean expressions.
Rules~\textsc{EqOp} and \textsc{DiffOp} define the evaluation of the
equality and difference between two expressions of the same type; the
result is a Boolean value. Rule~\textsc{Parenth} describes the
evaluation of a parenthesised expression.

% Natural operators.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{NatAdd}} \\
    {\begin{prooftree}

        % Evaluates e and e'.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}

        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e'}\xrightarrow{e}v'}

        % Conclusion.
        \infer2
        [$v+_{\mathbb{N}}v'\le\mathtt{NATMAX}$]
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{e}~+~\mathrm{e'}\xrightarrow{e}v~+_{\mathbb{N}}~v'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{NatSub}} \\
    {\begin{prooftree}

        % Evaluates e and e'.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e'}\xrightarrow{e}v'}

        % Conclusion.
        \infer2
        [$v\ge{}v'$]
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{e}~-~\mathrm{e'}\xrightarrow{e}v~-_{\mathbb{N}}~v'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{OrdOp}} \\
    
    {\begin{prooftree}

        % Evaluates e and e'.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e'}\xrightarrow{e}v'}

        % Conclusion.
        \infer2
        [$\mathrm{op}_{ordn}\in{}\{<,\le,>,\ge\}$]
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{e}~\mathrm{op}_{ordn}~\mathrm{e'}\xrightarrow{e}v~op_{ord\mathbb{N}}~v'
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

% Boolean operators.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{BoolBinOp}} \\
    {\begin{prooftree}

        % Evaluates e adn e'.
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e}\xrightarrow{e}v}
        \hypo{\Delta,\sigma,\Lambda&\vdash\mathrm{e'}\xrightarrow{e}v'}

        % Conclusion.
        \infer2
        [$\mathrm{op}_{bool}\in{}\{\mathtt{and},\mathtt{or}\}$]
        {
          \Delta,\sigma,\Lambda\vdash
          \mathrm{e}~\mathrm{op}_{bool}~\mathrm{e'}
          \xrightarrow{e}
          v~op_{\mathbb{B}}~v'
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{NotOp}} \\    
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}v}
        
        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\Lambda\vdash~$\vhdle|not|$~\mathrm{e}\xrightarrow{e}\lnot{}v
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

% Equality and difference.

\begin{table}[H]
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{EqOp}} \\
    
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}v}

        % Evaluates e'.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e'}\xrightarrow{e}v'}

        % Conclusion.
        \infer2
        {
          \Delta,\sigma,\Lambda\vdash\mathrm{e}~=~\mathrm{e'}\xrightarrow{e}eq(v,v')
        }
      \end{prooftree}} \\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{DiffOp}}  \\
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}~=~\mathrm{e'}\xrightarrow{e}v}

        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\Lambda\vdash
          \mathrm{e}~\neq~\mathrm{e'}
          \xrightarrow{e}\lnot{}v
        }
      \end{prooftree}}\\
  \end{tabular}
  \begin{tabular}{@{}l}
    {\fontsize{10}{13}\selectfont\textsc{Parenth}} \\
    
    {\begin{prooftree}

        % Evaluates e.
        \hypo{\Delta,\sigma,\Lambda\vdash\mathrm{e}\xrightarrow{e}v}

        % Conclusion.
        \infer1
        {
          \Delta,\sigma,\Lambda\vdash\mathtt{(}\mathrm{e}\mathtt{)}\xrightarrow{e}v
        }
      \end{prooftree}} \\
  \end{tabular}
\end{table}

In Rule~\textsc{EqOp}, $eq$ is the equality operator established for
all types defined in the semantics. In the definition of $eq$, two
natural numbers and two Booleans are compared with the Leibniz
equality. Two values of an array type are equal if the sub-elements
sharing the same index are equal; thus the two arrays must be of the
same size.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:
