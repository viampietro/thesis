% Chapter Template

\chapter{Introduction}
\label{chap:intro}

With the use of every human-bred technology is associated a
risk. Regarding the nature of the technology, and the broader system
in which it is involved, the consequences of a failure can be
dramatic. Thus arises the notion of the safety of systems;
\cite{Bowen1993} gives the following definition of safety:

\begin{center}
  ``Safety can [\dots] be defined as the freedom from exposure to
  danger, or the exemption from hurt, injury or loss.''
\end{center}

A \textit{safety-critical} system can be understood as a system for
which the safety aspect is the main concern, being that important
consequences, such as direct human losses, natural catastrophes, or
economic disasters, could result of the failure of the system. In this
thesis, conducted in the field of computer sciences, we are of course
particularly interested in safety-critical \textit{computer}
systems. The concept of computer system encompasses both the low-level
hardware-related and the more abstract software-related aspects
involved in computer technologies. Nowadays, computers pervade a
considerable number of objects and technologies that pave our
every-day life, including safety-critical systems. Thus, the risk
associated with the use of computers in certain critical applications
is real. Failures of safety-critical computer systems have happened
and continue happen; the list of critical incidents maintained by the
ACM Committee on Compters and Public Policy and Peter G. Neumann ever
since the mid 80s \cite{Neumann1994} is always growing\footnote{The
  \emph{risks digest} website continues to register the
  computer-related incidents that resulted or could result in
  important damages: \url{https://catless.ncl.ac.uk/Risks/} }.

To ensure the safety of computer systems involved in critical domains
such as avionics, railway, power plants or medicine, there exists a
number of standards and norms developed by international
organizations. These standards set of a number of rules and techniques
to be followed for the design, the production and the validation of
safety-critical computer systems. To cite some well-known standards,
the \href{https://www.eurocae.net/}{EUROCAE} and
\href{https://www.rtca.org/}{RTCA} organisms has devised the
ED-12C/DO-178C and ED-80/DO-254 industry standards for the development
cycle of software and hardware computer systems involved in avionics;
the \href{https://www.cencenelec.eu/}{CENELEC} has defined the
EN-50128 standard for the development of softwares for railway control
and protection systems; the \href{https://www.iec.ch}{IEC} is at the
origin of the IEC-60880 standard for the development of softwares
involved in the control of power plants. In this thesis, we are
interested in verifying a \textit{computer-related} methodology
involved in the production of safety-critical medical devices; thus,
we need to cite the EU 2017/145 regulation
text\footnote{\url{http://data.europa.eu/eli/reg/2017/745/2020-04-24}}
that sets the standard for the development of medical devices,
including how to validate the technologies involved in the production
line.

The rules imposed by the standards vary with respect to the criticity
of the considered systems; for instance, in the medical field, the
regulation text 2017/145 of the EU, pertaining to the marketing of
medical devices, sets a different requirement level whether we are
considering the production of dressings (level 0), or of
neuroprotheses (highest-level, level 4). The IEC does the same by
defining of SIL (Safety Integrity Level) measure that qualifies the
criticity level of a system.

Among the mandatory procedures, prescribed by the standards, that must
be followed to validate a computer system involved in a
safety-critical system, tests (unit, functional or integration tests)
or simulation (especially applied to hardwares) are to be noted.
However, in the case of the development safety-critical computer
systems, a particular kind of methods, called \textit{formal methods}
(FM), are also applied. In formal methods applied to computer systems,
a computer system is considered as a mathematical object
\cite{Bjorner2014}. As pointed out in \cite{Bowen1993}, ``formal
methods address \textit{correctness} issues'', that is whether or not
a system delivers the required service. The perks of formal methods
are to set a formal mathematical framework around a computer system.
This framework will permit to reason about the system and to prove
that the system meets some required properties. Thus, a ``formal
methods'' framework for computer systems needs at least a formal
requirement language, i.e. with a formal semantics, to express the
properties that a given system must verify. The expression of these
required properties is called the \textit{specification} of the
system.  On the hardware side, we can cite some specification
formalisms such as CCS \cite{Milner1980}, CSP \cite{Hoare1978}, Petri
nets \cite{Petri1962} or TLA+ \cite{Lamport1994} to describe reactive
systems (i.e. systems that continuously interact with an environment);
hardware description languages such as \vhdl{} \cite{Lipsett1986} and
\textsf{Verilog} \cite{IEEE1996} can also be considered as formal
specification languages for hardware designs if provided with a formal
semantics and embedded in a formal proof system (see for instance
\cite{Borrione1992}). On the software side, we can cite specification
languages such as VDM \cite{Bjorner1987a}, the Z notation
\cite{Abrial2013} on which is based the B language \cite{Abrial1991}
(included in the broader B-method); but also, all the theorem provers
and proof assistants that come with their own specification languages
such as \isahol{} \cite{Nipkow2002}, \coq{} \cite{Coq2021},
\textsf{PVS} \cite{Crow1995}, etc.  A FM framework must also provide a
formal proof system to reason about the formal specification of the
system. Some FM frameworks come with means to implement the computer
system or simplified version of the system (i.e. a model) in a formal
setting. This latter kind of framework enables to check if the
implementation of a system always complies with its specification,
i.e. the \textit{correctness/soundness} of the system, and if all the
aspects of the specification are met by the implementation, i.e. the
\textit{completeness} of the system.

Even though the purpose is always to check the correctness of systems,
there exist multiple kinds of formal verification techniques. These
techniques can be separated in two groups. The first group refers to
the techniques for which a human \textit{programmer} is involved in
the deduction process that aims at establishing some proofs over a
computer system; we refer to these techniques as \textit{deductive
  verification} methods. The second group refers to the techniques for
which the proof search is automatic; we refer to them as
\textit{automatic theorem proving} techniques.  The techniques applied
to the formal verification of hardware computer systems or software
computer systems are quite similar.  Thus, most of the techniques
presented here apply to both hardware and software developments. Note
that the following presentation of formal verification techniques is
not exhaustive.

\paragraph{Symbolic execution}
Symbolic execution \cite{Boyer1975} aims at the automatic static
analisys of programs. The method consists in generating all the
execution traces, also called \textit{symbolic} traces, of a given
program; the result takes the form of a symbolic execution tree. In
these traces, some of the program inputs, i.e. the \textit{variables},
will be associated with \textit{symbolic} expressions denoting the
fact that the values of these inputs are yet unknown. Thus, by
reasoning on the definition domains of these inputs, some properties
of the program can be checked at execution points, that is, at the
nodes of the symbolic execution tree. The property checking process is
most of the time performed by a constraint solver \cite{Amadini2020},
where constraints are expressed over the \textit{symbolic} variables
of the program. Pertaining to the construction of the symbolic
execution tree, it is obtained most of the time by applying the rules
of a structural formal semantics \cite{Plotkin2004} associated with
the language of the considered program. Typically, a branching in the
execution tree is the result of the evaluation of a conditional
statement. Each path of the execution tree is associated with a
satisfiability condition, i.e. a Boolean formula, that determines if a
given execution point is reachable or not.

\paragraph{Abstract interpretation}
Abstract interpretation \cite{Cousot1977} aims at the static analysis
of programs by approximating the possible execution states of the
program. To do so, the concrete domains of the program variables are
related to more abstract domains notably through the use of a lattice
structure. Afterwards, invariant properties that the program verifies
can be automatically checked against the lattice structure. For
instance, abstract interpretation can help to determine if a given
program terminates.

\paragraph{Model checking}
Model checking techniques \cite{Queille1982, Clarke1986} build a model
reflecting the execution of a computer system by enumerating all the
possible execution states of the system. Then, the \textit{execution}
model can be automatically checked against some properties that the
computer system must verify. The execution model must be a
finite-state model, i.e. the enumeration of the execution states of
the model must not be infinite.  Most of the time, the properties that
the computer system must verify are expressed through formulas of a
modal logic.  Model-checking techniques are broadely used for the
formal verification of reactive systems, especially hardware
systems. In that case, the properties that must be met by the
considered system are expressed within formulas of the Linear Temporal
Logic (LTL) \cite{Pnueli1977}, which are handy to express time-related
properties.

\paragraph{Interactive deductive verification}
In the philosophy of deductive verification, the programmer is
responsible for the specification and the implementation of a computer
system, but he also expresses theorems and conducts the corresponding
proofs in a formal proof system. Deductive verification methods are
closely tied to proof assistants (cf. \isahol{}, \coq{}, \textsf{PVS},
etc.), which offer the possibility to specify, implement, perform
proofs over a given program in the same framework.  The programmer
build the proof for a given theorem in an interactive manner, for
instance assisted by a \textit{tactic} language in the case of the
\coq{} proof assistant (see Chapter~\ref{chap:prelim-notions} for an
example). Contrary to the case of automatic theorem proving, there are
not many different \textit{techniques} to perform interactive theorem
proving; however, each proof assistant comes with its own
specification language and
underlying proof system.\\

In this thesis, we address the problem of the formal verification of a
particular program. This program transforms an input model, which is
an instance of a particular kind of Petri nets (PNs), into a program
written in a Hardware Description Language (HDL). The program, the
context in which it is involved, the specificities of the input model,
and the target HDL, will all thoroughly be presented in this
thesis. Here, we only want to zoom in on the nature of the considered
program submitted to the process of formal verification. The
transformation from an instance of one formalism to another instance
of another formalism is analog to the case of a \textit{compiler}
program. The only difference is that here an input to the
transformation is not a program of a source \textit{language}, but
rather a model of an abstract source formalism, namely a PN model.
Thus, our formal verification task amounts to the formal
\textit{certification} of a compiler program. Here, we use the word
\textit{certification} to stay as general as possible because compiler
\textit{verification} already designates a particular way of proving
that a compiler is \textit{safe}. The problem of compiler
certification has greatly stimulated the use of formal methods in the
field of software verification. Because a complete computer system is
made out of complete chain of hardware, firmware and software
components, the ultimate goal of the verification of such a system is
to be able to prove the safety of all the layer composing it. In this
system of layers, the place of compiler programs are mandatory as they
are placed at the layer interfaces. Indeed, one can prove that a given
program and a given hardware is safe, but what if the compilation
phase from the given program to low-level version introduces errors
and behavior divergences. With these considerations in mind, compiler
certification because very critic aspect for one that needs to certify
a full computer system.

Thus, certifying a compiler program amounts to proving that the
compiler verifies certain properties; \cite{Patrignani2019} presents
three of them. First, one can verify that a compiler is
\textit{type-preserving}. A type-preserving compiler yields a
well-typed target program given a well-typed source program. Second,
one can verify that a compiler is \textit{semantic-preserving}. a
semantic-preserving compiler yields a target program that behaves
similarly to the source program. Thirdly, one can verify that the
compiler is \textit{equivalence-preserving}. Given two source programs
that verify a certain \textit{source-level} equivalence relation, an
equivalence-preserving compiler yields two corresponding target
programs that verify a certain \textit{target-level} equivalence
relation; this target-level equivalence relation is of course somehow
related to the source-level equivalence relation. In this thesis, we
are interested in proving that \textit{compiler-like} transformation
program is \textit{semantic-preserving}.

\cite{Leroy2009} lists several techniques that exist to establish that
a compiler is semantic-preserving.

The first is called compiler verification. Compiler verification aims
at establishing the semantic-preserving property of a compiler program
by proving a so-called semantic preservation theorem of the form:

\begin{center}
  For all source program $S$, and compiler $C$ from the language of
  $S$ to a target language, $S$ has the behavior $B$ (written $S$) iff
  $C(S)$
  (i.e. the compiled version of $S$) has the behavior $B$:\\

  $\forall{}S,C,B$,
  $S\Downarrow{}B\Leftrightarrow{}C(S)\Downarrow{}B$.
  
\end{center}

Now the above form of the theorem is the strongest one, i.e. it can be
proved only for a very particular kind of source and target
languages. Other refined versions of this semantic preservation
theorem exist depending on the nature of the source and target
languages. Proving such a theorem is often performed with the help of
a proof assistant as can be witnessed in the pioneering work on the
\ccert{} compiler \cite{Leroy2006}; thus, compiler verification falls
under the hood of deductive verification methods. 

The second method to compiler certification is called compiler
\textit{validation}. In that case, no theorem are directly proved over
the compiler program. However, the compiler is associated with another
verification technique (that could one of these cited above) that will
validate the fact that the generated target program behaves in the
same manner as the source program. This validation step is performed
after the compilation.

The third method is called \textit{proof-carrying} compilation. In
this setting, the compiler program generates alongside the target
program a proof that this program conforms to some property. The
generated proof must be is such a format that can be verified by a
\textit{proof-checker}, built in a proof assistant for instance.

In the thesis, we will follow the compiler verification
technique. Consequently, our aim is to prove a semantic preservation
theorem over a transformation program and to mechanize the process
within the framework of the \coq{} proof assistant.

This thesis memoir is structured as follows.

Chapter~\ref{chap:hilecop} presents the context of our work, namely
the \hilecop{} methodology, which describes a process to design and
produce safety-critical digital systems. This chapter explains which
part of the methodology, i.e. the transformation program we talked
about above, refered to as the \hilecop{} transformation, we propose
to formally verify; it also exposes our research question(s) with
respect to this task.  Chapter~\ref{chap:prelim-notions} introduces
all the necessary mathematical notions to comprehend the remainder of
the memoir.  Chapter~\ref{chap:hilecop-models} presents in an informal
and formal way a specific kind of Petri net models; these models are
the input to the \hilecop{} transformation program.
Chapter~\ref{chap:hvhdl} gives an informal presentation of the \vhdl{}
language. The \vhdl{} language is the target language in which the
programs generated by the \hilecop{} transformation are written. We
also give in this chapter a formal definition of the syntax and
semantics of a subset of the \vhdl{} language that we have baptised
\hvhdl{}.  Chapter~\ref{chap:transformation} presents the algorithm of
the \hilecop{} transformation and its implementation with the \coq{}
proof assistant.  Chapter~\ref{chap:proof} details the semantic
preservation theorem expressing that the \hilecop{} transformation is
semantic-preserving.  It also gives the high-level theorems and lemmas
involved in the proof of the semantic preservation theorem.  Finally,
Chapter~\ref{chap:concl} ends the memoir, and outlines the
perspectives regarding the full completion of the task of proving that
the \hilecop{} transformation is semantic-preserving.

The results of a literature review pertaining to the formal semantics
\vhdl{} is presented at the beginning of
Chapter~\ref{chap:hvhdl}. Similarly, the results of a literature
review pertaining to the task of compiler verification in the world of
deductive verification methods are presented at the beginning of
Chapters~\ref{chap:transformation} and \ref{chap:proof}.

All the programming tasks of this thesis have been performed within
the framework of the \coq{} proof assistant. The produced code, of
which some fragments are presented all along this thesis memoir, is
fully accessible under the following \textsf{Git} repository:

\begin{center}
  \url{https://github.com/viampietro/ver-hilecop}
\end{center}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
