The work of mechanizing the proof of the \nameref{thm:full-bisim}
theorem is an ongoing task. At the time of the writing, we have only
verified thirty per cent of the proof concerning the
\nameref{lem:sim-init-states} lemma. However, the effort to achieve
this thirty per cent of the verification amounts to three months of
work. In this section, we give metrics to measure the gap between the
size of the ``paper'' proof (see Appendix~\ref{app:sem-preserv-proof})
and the size of the computer-checked proof written in \coq{}. We point
out some of the reasons that may explain the gap, and comment some
employed techniques to reduce the size of proof scripts. As a
remainder, the full code including specifications and proof scripts is
available at \todo{add ref to git repo}.

Listing~\ref{lst:coq-bisim-thm} presents the \coq{} implementation of
Theorem~\ref{thm:full-bisim} along with the sequence of tactics
constituting its proof. We also declared the \nameref{thm:beh-pres}
theorem, and the \nameref{thm:elab-ex}, \nameref{thm:init-ex},
\nameref{thm:sim-ex} theorems as axioms in the \texttt{Soundness.v}
file under the \texttt{soundness} folder of the Git repository.

\begin{lstlisting}[language=coq,caption={\coq{} implementation of the \nameref{thm:full-bisim} theorem and the mechanized version of its proof.},label={lst:coq-bisim-thm}]
Theorem sitpn2hvhdl_full_bisim :
  forall $\tau$ sitpn decpr $id_{ent}$ $id_{arch}$ $E_c$ $\theta_s$ d $E_p$ mm $\theta_\sigma$ $\gamma$ $\Delta$,

    (* sitpn is well-defined. *)
    IsWellDefined sitpn ->
    
    (* sitpn translates into (d, $\gamma$). *)
    sitpn_to_hvhdl sitpn decpr $id_{ent}$ $id_{arch}$ mm = (inl (d, $\gamma$)) ->

    (* Environments are similar. *)
    SimEnv sitpn $\gamma$ $E_c$ $E_p$ ->
    
    (* SITPN sitpn yields execution trace $\theta_s$ after $\tau$ execution cycles. *)
    SitpnFullExec sitpn $E_c$ $\gamma$ $\theta_s$ ->    
    
    (* Design d yields simulation trace $\theta_\sigma$ after $\tau$ simulation cycles. *)
    hfullsim $E_p$ $\tau$ $\Delta$ d $\theta_\sigma$ ->
    
    (* ** Conclusion: traces are similar. ** *)
    SimTrace $\gamma$ $\theta_s$ $\theta_\sigma$.
Proof.  
  (* Case analysis on $\tau$ *)
  destruct $\tau$;
    intros *;
    inversion_clear 4;
    inversion_clear 1;

  (* - CASE $\tau$ = 0, GOAL $\gamma\vdash{}s_0\sim\sigma_0$. Solved with sim_init_states lemma. 
     - CASE $\tau{}>0$, GOAL $\gamma\vdash(s_0 :: s_0 :: s :: \theta)\sim{}(\sigma_0 :: \sigma :: \sigma' :: \theta'')$.  
     Solved with [first_cycle] and [simulation] lemmas. *)
    lazymatch goal with
    | [ Hsimloop: simloop _ _ _ _ _ _ _ |- _ ] =>
      inversion_clear Hsimloop; constructor; eauto with hilecop
    end.
Qed.
\end{lstlisting}

The proof laid out in Listing~\ref{lst:coq-bisim-thm} follows the
structure of the informal proof of Theorem~\ref{thm:full-bisim}.
First, we perform case analysis on the structure of the $\tau$
variable through the \texttt{destruct} tactic. Then, the
$\mathtt{intros}~*$ introduces all universally-bound variables in the
proof context. Then, at Lines~25 and 26, we use a variant of the
\texttt{inversion} tactic (i.e. \texttt{inversion\_clear}) to unfold
the definition of the SITPN full execution relation and the \hvhdl{}
full simulation relations. The number passed as an argument to the
\texttt{inversion\_clear} tactic refers to the index of the premise in
the arrow-separated list of premises constituting the declaration of
the theorem. At Line 31, we perform pattern matching on the proof
context and on the conclusion to be proved. This permits to identify
the hypothesis associated to the \hvhdl{} simulation relation; we name
it \texttt{Hsimloop}. This hypothesis has been introduced in the
context of the proof as a side effect of the inversion \texttt{tactic}
used at Line 26. Then, we introduce in the proof context new
hypotheses based on the definition of the \texttt{Hsimloop} hypothesis
(i.e. the definition of the \hvhdl{} simulation relation) by invoking
\texttt{inversion\_clear} tactic on \texttt{Hsimloop}. Then, the
\texttt{constructor} tactic builds sub-goals to be proved based on the
definition of the full trace similarity relation (i.e. ). We let the
\texttt{eauto} tactic decide which lemma apply to solve the sub-goals
generated by the \texttt{constructor} tactics. We give a hint to the
\texttt{eauto} tactic so that it looks in the user-defined
\texttt{hilecop} database of theorems and lemmas to solve the
sub-goals. The \texttt{hilecop} database contains the \coq{}
implementation of all the theorems and lemmas used to prove the
\nameref{thm:full-bisim} theorem.

\paragraph{Robustness to change}
\label{sec:robustness}

The proof laid out in Listing~\ref{lst:coq-bisim-thm} is
representative of our strategy to keep our mechanized proofs robust to
change. The robustness criterion is important for multiple reasons.
First, in the proceeding of the proof, we can always realize that some
case is missing in the expression of the transformation function or
discover that the semantics of the SITPNs or the \hvhdl{} language is
incomplete or incorrect. Therefore, we want to structure our proofs in
a way that will lower the impact of correcting the transformation
function or completing the semantics. Second, we know that the SITPN
structure and the \hvhdl{} code of the place and transition designs
will be evolving in the future. Therefore, we want to be able to adapt
our proofs with a minimum effort. To reach robustness to change, we
follow the indications laid out in \cite{Chlipala2010}. Mainly, we
make an important use of the pattern matching constructs, such as
\texttt{lazymatch} or \texttt{match}, to seek hypotheses in the
current proof context. Also, we build hint databases and rely as much
as possible on the use of the \texttt{auto} and \texttt{eauto} to
solve the conclusions.

\paragraph{Automation}

To shorten the size of proofs, we develop user-defined tactics using
the \coq{} \texttt{Ltac} language. The tactic that most contributed to
the reduction of the size of the proof scripts is the \texttt{minv}
tactic (see \texttt{StateAndErrorMonadTactics.v} under the
\texttt{common} folder). The \texttt{minv} tactic automate the proof
of certain lemmas regarding the properties of the \hilecop{}
transformation function in the context of the state-and-error monad.
Our \coq{} implementation of the \hilecop{} transformation function
implements the state-and-error monad. This monad simulates imperative
language traits into functional languages. All functions involve in
the \hilecop{} transformation function carry a compile-time state,
defined as the \coq{} type \texttt{CompileTimeState}. Each function
either return a value, modify the compile-time state or do both. To
give an example of the use of the \texttt{minv} tactic,
Listing~\ref{lst:gen-p-comp-inst} shows the implementation of the
\texttt{generate\_place\_comp\_inst} function involved in \hilecop{}
transformation function. The \texttt{generate\_place\_comp\_inst}
function generates a \hvhdl{} PCI statement from a place $p$ passed as
a parameter. As a side effect, the
\texttt{generate\_place\_comp\_inst} function adds the PCI statement
to the behavior of the top-level design currently built in the
compile-time state.

\begin{lstlisting}[language=coq,caption={\coq{} implementation of the \texttt{generate\_place\_comp\_inst} function; the function takes an SITPN place $p$ as a parameter, and modifies the compile-time state without returning a value (i.e. the function return type is \texttt{unit})},label={lst:gen-p-comp-inst}]
Definition generate_place_comp_inst (p : P sitpn) : CompileTimeState unit :=

   do id         <- get_nextid;
   do _          <- bind_place p id;
   do pcomp      <- get_pcomp p;
   do pcomp_inst <- HComponent_to_comp_inst id place_entid pcomp;
   add_cs pcomp_inst.
\end{lstlisting}

In its definition body, function \texttt{generate\_place\_comp\_inst}
sequentially calls to functions that sometimes modify the compile-time
state (e.g. the \texttt{bind\_place} function adds a binding between
$p$ and $id$ in the generated $\gamma$ binder, i.e. $\gamma(p)=id$
after the call to \texttt{bind\_place}), or sometimes simply return a
value without modifying the state (e.g. \texttt{get\_pcomp} returns an
intermediate structure representing the place component instance
associated to place $p$ in the compile-time state). During the
mechanization of the proof, we often need to prove that some
properties hold between the input compile-time state and the output
compile-time after the call to a certain function. For example, after
calling the \texttt{generate\_place\_comp\_inst} function on a given
place $p$ and for a given input state $s$, let us say that a new
compile-time state $s'$ is returned. We want to show that the part of
the $\gamma$ binder pertaining to the binding of transitions to TCI
identifiers has not changed between state $s$ and state
$s'$\footnote{Remember that the $\gamma$ binder is part of the
  compile-time state record type.}. To perform the proof, we need to
show that each function call composing the sequence of the
\texttt{generate\_place\_comp\_inst} function returns a compile-time
state verifying the wanted property. Proving simple property like
verifying that part of the compile-time states are equal through the
multiple invocation of functions is highly automatable. We adapt the
tactic \texttt{monadInv} defined in the \ccert{} project
\cite{Leroy2009} to automate proof for such properties. The result is
the tactic \texttt{minv} massively used in the proofs pertaining to
state invariants\footnote{State invariance lemmas are to be found in
  the \texttt{GenerateInfosInvs.v},
  \texttt{GenerateArchitectureIns.v}, \texttt{GeneratePortsInvs.v} and
  \texttt{GenerateHVhdlInvs.v} under the \texttt{sitpn2hvhdl} folder
  of the Git repository.}.


\paragraph{Gap between informal and formal proof}

There is a huge gap of size between the informal proof of the
\nameref{thm:full-bisim} theorem given in this Chapter and in
Appendix~\ref{app:sem-preserv-proof} and the machine-checked formal
proof. Right now, the \coq{} proof wins the size competition. The most
significant distance between the size of the informal and the formal
proof comes from the two following points: the statement of the
combinational equations defining the value of \hvhdl{} signals and the
statement of properties about the \hilecop{} transformation
function. Stating that a combinational equation holds for a given
signal in the context of an informal proof is a one-line sentence. The
same goes when invoking the properties of the PCIs and TCIs populating
the top-level design behavior based on the definition of the
transformation function. However, proving these statements represents
a tremendous mechanization effort within the \coq{} proof
assistant. To give an example, we begin the proof of
Lemma~\ref{lem:init-states-eq-marking} by taking a place $p$ and a PCI
identifier $id_p$ linked through the $\gamma$ binder returned by the
transformation function. Then, we state the existence of a PCI
statement, identified by $id_p$ and with an associated generic map,
input port map and output port map, in the behavior of the top-level
design returned by the transformation function. To do so, we use the
following the sentence:

\begin{center}
  ``Let us take a $p\in{}P$ and an $id_p\in{}Comps(\Delta)$ such that
  $\gamma(p)=id_p$. By construction, there exist $gm_p,ipm_p,opm_p$
  s.t. $\mathtt{comp}(id_p,"place",gm_p,ipm_p,opm_p)\in{}d.cs$.''
\end{center}

The expression ``by construction'' is a shorthand for ``knowing how
the target \hvhdl{} design is constructed by the transformation
function'', or ``based on the definition of the transformation
function''. In \coq{}, proving the lemma that states the existence of
a PCI for a given place $p$ amounts to $1500$ lines of proof
script. The lemmas regarding properties of PCI and TCI statements
deduced from the transformation function tend to have complicated
proofs. We believe that the implementation of the \hilecop{}
transformation function could be more straightforward in order to
simplify this kind of proof. By straightforward, we mean that the
number of steps separating a given place or a given transition from
the generation of their corresponding PCI or TCI could be diminished,
maybe at the cost of time performance. Right now, ease of proof is
more important than time performance, considering that our goal is to
prove the semantic preservation theorem in a reasonable amount of
time. Still, the major complexity of the transformation function, i.e.
what makes the proofs so hard, lies in the generation of the
interconnections between PCIs and TCIs. Some engineering effort could
be spent to simplify this particular of the transformation.

Also, we spent a lot of time proving some uninteresting, however
necessary, properties about the \hvhdl{} design states and the
\hvhdl{} simulation relations. For instance, we proved a lot of lemmas
pertaining the preservation of identifiers through the simulation
phases (e.g if a signal id is present in a design state at the
beginning of a stabilization phase, then it is still present at the
end of the phase). We also proved a lot of uninteresting properties
about the \hvhdl{} elaborated designs and the \hvhdl{} elaboration
relation. For instance, properties on the uniqueness of identifiers in
design states, in elaborated designs\dots We believe that a more
systematic use of dependent types, especially to implement the
\hvhdl{} design state and the elaborated design structure, could
prevent us from proving this kind of lemmas.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:
